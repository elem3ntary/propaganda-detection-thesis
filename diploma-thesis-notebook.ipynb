{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Installing packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-22T10:50:13.222502Z",
          "iopub.status.busy": "2024-04-22T10:50:13.222183Z",
          "iopub.status.idle": "2024-04-22T10:50:39.816337Z",
          "shell.execute_reply": "2024-04-22T10:50:39.815130Z",
          "shell.execute_reply.started": "2024-04-22T10:50:13.222478Z"
        },
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.1)\n",
            "Collecting seaborn\n",
            "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.22.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.24.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.10/dist-packages (from seaborn) (1.5.3)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.10/dist-packages (from seaborn) (3.8.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.5)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.2.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
            "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentencepiece, seaborn\n",
            "Successfully installed seaborn-0.13.2 sentencepiece-0.2.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install transformers seaborn sentencepiece\n",
        "%pip install --upgrade --no-cache-dir gdown > /dev/null"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xinNpVFYItsZ"
      },
      "source": [
        "# Importing libraries and config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-22T10:50:39.819849Z",
          "iopub.status.busy": "2024-04-22T10:50:39.819486Z",
          "iopub.status.idle": "2024-04-22T10:50:49.259970Z",
          "shell.execute_reply": "2024-04-22T10:50:49.259171Z",
          "shell.execute_reply.started": "2024-04-22T10:50:39.819806Z"
        },
        "id": "FGuCL9hz_67h",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import gdown\n",
        "import os\n",
        "import logging\n",
        "import sys\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from time import time\n",
        "from collections import Counter\n",
        "from tqdm.auto import tqdm\n",
        "from sklearn.metrics import f1_score, recall_score, precision_score, accuracy_score\n",
        "from torch.optim import AdamW\n",
        "from warnings import filterwarnings\n",
        "from transformers import MarianMTModel, MarianTokenizer\n",
        "from functools import partial\n",
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-22T10:50:49.261640Z",
          "iopub.status.busy": "2024-04-22T10:50:49.261166Z",
          "iopub.status.idle": "2024-04-22T10:50:49.268451Z",
          "shell.execute_reply": "2024-04-22T10:50:49.267645Z",
          "shell.execute_reply.started": "2024-04-22T10:50:49.261613Z"
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Configuring libraries\n",
        "logging.basicConfig()\n",
        "tqdm.pandas()\n",
        "filterwarnings('ignore')\n",
        "\n",
        "\n",
        "# Remove all handlers associated with the root logger object.\n",
        "for handler in logging.root.handlers[:]:\n",
        "    logging.root.removeHandler(handler)\n",
        "\n",
        "# Configure logging to output to stdout, which should display in a Kaggle notebook.\n",
        "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
        "logger = logging.getLogger('app')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-22T10:50:49.271228Z",
          "iopub.status.busy": "2024-04-22T10:50:49.270925Z",
          "iopub.status.idle": "2024-04-22T10:50:49.278149Z",
          "shell.execute_reply": "2024-04-22T10:50:49.277300Z",
          "shell.execute_reply.started": "2024-04-22T10:50:49.271196Z"
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# %pip install --no-cache-dir --upgrade kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-22T10:50:49.279607Z",
          "iopub.status.busy": "2024-04-22T10:50:49.279334Z",
          "iopub.status.idle": "2024-04-22T10:50:49.287295Z",
          "shell.execute_reply": "2024-04-22T10:50:49.286544Z",
          "shell.execute_reply.started": "2024-04-22T10:50:49.279576Z"
        },
        "executionInfo": {
          "elapsed": 5674,
          "status": "ok",
          "timestamp": 1711466667816,
          "user": {
            "displayName": "Стефан-Юрій Малик",
            "userId": "15188954823949757311"
          },
          "user_tz": -120
        },
        "id": "k3GevJeY__Ny",
        "outputId": "58c1a74c-e4b0-4eab-9b9a-dfbb24642b06",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Installing Kaggle CLI used for pushing notebook to kaggle if working elsewhere\n",
        "# %%bash\n",
        "# !gdown 1GkE7Y9FYq2sczsusvhWsvvRkyrljYULF -O kaggle.json\n",
        "# !mkdir -p ~/.kaggle\n",
        "# !mv ./kaggle.json ~/.kaggle/\n",
        "# !chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utt2UGdLIx_w"
      },
      "source": [
        "# Functions for dataset processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-22T10:50:49.288951Z",
          "iopub.status.busy": "2024-04-22T10:50:49.288616Z",
          "iopub.status.idle": "2024-04-22T10:50:49.304150Z",
          "shell.execute_reply": "2024-04-22T10:50:49.303273Z",
          "shell.execute_reply.started": "2024-04-22T10:50:49.288923Z"
        },
        "id": "nXuw2ISy_Te6",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class DatasetFields():\n",
        "    message_id = 'message_id'\n",
        "    text = 'text'\n",
        "    label = 'label'\n",
        "    channel = 'channel'\n",
        "    date = 'date'\n",
        "    lang = 'ua_lang_chars'\n",
        "    sourced_lang = 'sourced_lang'\n",
        "\n",
        "    propaganda_label = 1\n",
        "    factual_label = 0\n",
        "\n",
        "    label_title_mapping =   {\n",
        "            propaganda_label: 'Propaganda',\n",
        "            factual_label: 'Factual'\n",
        "        }\n",
        "\n",
        "    label_to_color = {\n",
        "        propaganda_label: 'r',\n",
        "            factual_label: 'g'\n",
        "    }\n",
        "\n",
        "    @staticmethod\n",
        "    def get_feature_list():\n",
        "        return [\n",
        "            DatasetFields.message_id,\n",
        "            DatasetFields.text,\n",
        "            DatasetFields.label,\n",
        "            DatasetFields.channel,\n",
        "            DatasetFields.date,\n",
        "            DatasetFields.sourced_lang\n",
        "        ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "parser_column_mapping = {\n",
        "      'id': DatasetFields.message_id,\n",
        "      'raw_text': DatasetFields.text,\n",
        "}\n",
        "\n",
        "parser_column_type_mapping = {\n",
        "      'message_id': int,\n",
        "      'views': int,\n",
        "      'text': str\n",
        "      # per docs of pandas str will be displayed as object\n",
        "      # when calling df.dtypes\n",
        "\n",
        "\n",
        "      # type of `date` column in computed in `cast_types`\n",
        "      # `date` column contains dates in UTC+0\n",
        "}\n",
        "\n",
        "def rename_columns(df, column_mapping):\n",
        "    return df.rename(columns=column_mapping)\n",
        "\n",
        "def handle_missing_values(df):\n",
        "    # We have no use of messages with missing message text\n",
        "    # Therefore we drop them\n",
        "    df['text'] = df['text'].replace('', np.nan)\n",
        "    df = df.dropna(subset=['text'])\n",
        "\n",
        "    # If message does not contain views we drop it since\n",
        "    # Message either is empty or cannot be displayed due to\n",
        "    # Telegram's TOS refert to `empty_views_message_text` function\n",
        "    df = df.dropna(subset=['views'])\n",
        "\n",
        "    return df\n",
        "\n",
        "def cast_types(df, column_type_mapping):\n",
        "    df =  df.astype(column_type_mapping)\n",
        "    df['date'] = pd.to_datetime(df['date'])\n",
        "\n",
        "    return df\n",
        "\n",
        "def set_label(df, label):\n",
        "    df[DatasetFields.label] = label\n",
        "    return df\n",
        "\n",
        "def channel_url_to_name(df):\n",
        "    df['channel'] =  df['channel'].apply(lambda x: x.replace('https://t.me/', ''))\n",
        "    return df\n",
        "\n",
        "\n",
        "def set_static_col(df, name, value):\n",
        "    df[name] = value\n",
        "    return df\n",
        "\n",
        "\n",
        "def detect_language(message):\n",
        "    # NOT WORKING\n",
        "    ukrainian_charset = set('ґєії')\n",
        "    for c in message:\n",
        "        if c in ukrainian_charset:\n",
        "            return True\n",
        "\n",
        "    return False\n",
        "\n",
        "def detect_language_df(df):\n",
        "\n",
        "\n",
        "    tqdm.pandas(desc='Detecting lang')\n",
        "    df[DatasetFields.lang] = df['text'].progress_apply(detect_language)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-22T10:50:49.305637Z",
          "iopub.status.busy": "2024-04-22T10:50:49.305398Z",
          "iopub.status.idle": "2024-04-22T10:50:49.324676Z",
          "shell.execute_reply": "2024-04-22T10:50:49.323774Z",
          "shell.execute_reply.started": "2024-04-22T10:50:49.305616Z"
        },
        "id": "B2fmjJrFF1qN",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def get_dataset_from_file(filename: str):\n",
        "    if 'https://drive.google.com/' in filename:\n",
        "        temp_path = 'temp.csv'\n",
        "        gdown.download(filename, temp_path, fuzzy=True)\n",
        "\n",
        "        filepath = temp_path\n",
        "    else:\n",
        "        filepath = filename\n",
        "\n",
        "    return pd.read_csv(filepath)\n",
        "\n",
        "def download_from_drive(file_id, target_path=None):\n",
        "    logging.info(f'Downloading %s %s' % (file_id, \n",
        "                                         '' if target_path is None else 'to path ' + target_path))\n",
        "    if target_path is not None:\n",
        "        return gdown.download(f'https://drive.google.com/uc?id={file_id}', target_path) \n",
        "    return gdown.download(f'https://drive.google.com/uc?id={file_id}') \n",
        "\n",
        "def generate_dataset_from_subsets(custom_dataset_processor=None):\n",
        "    # Download datasets\n",
        "    factual_path = 'factual_uk.csv'\n",
        "    propaganda_path = 'propaganda_ru.csv'\n",
        "\n",
        "    if not os.path.exists(propaganda_path):\n",
        "        download_from_drive('1EG3iA5ne8dmKfmao0hxrHQSwRAA3WKKi', propaganda_path)\n",
        "\n",
        "    if not os.path.exists(factual_path):\n",
        "        download_from_drive('1Ntr9A3kAAdLuifGcb0slAOCgHrNelYlP', factual_path)\n",
        "\n",
        "    # Language agnostic df setup\n",
        "\n",
        "    propaganda_df = pd.concat([\n",
        "    (\n",
        "    pd.read_csv(propaganda_path, index_col=0)\n",
        "    .pipe(rename_columns, column_mapping=parser_column_mapping)\n",
        "    .pipe(handle_missing_values)\n",
        "    .pipe(cast_types, column_type_mapping=parser_column_type_mapping)\n",
        "    .pipe(set_label, label=DatasetFields.propaganda_label)\n",
        "    .pipe(channel_url_to_name)\n",
        "    # .pipe(detect_language_df)\n",
        "    .pipe(set_static_col, DatasetFields.sourced_lang, 'ru')\n",
        "    ),\n",
        "    # to add another dataset include its pipeline\n",
        "    ], axis=0, ignore_index=True)\n",
        "    factual_df = pd.concat([\n",
        "    (\n",
        "    pd.read_csv(factual_path, index_col=0)\n",
        "    .pipe(rename_columns, column_mapping=parser_column_mapping)\n",
        "    .pipe(handle_missing_values)\n",
        "    .pipe(cast_types, column_type_mapping=parser_column_type_mapping)\n",
        "    .pipe(set_label, label=DatasetFields.factual_label)\n",
        "    .pipe(channel_url_to_name)\n",
        "    # .pipe(detect_language_df)\n",
        "    .pipe(set_static_col, DatasetFields.sourced_lang, 'uk')\n",
        "    ),\n",
        "    get_language_inversed_dataset(subset='train')\n",
        "        .pipe(set_static_col, DatasetFields.sourced_lang, 'ru')\n",
        "    ], axis=0, ignore_index=True)\n",
        "\n",
        "    dataset = pd.concat([\n",
        "    propaganda_df, factual_df\n",
        "    ], axis=0, ignore_index=True).sample(frac=1).reset_index(drop=True)\n",
        "    assert all(feature in factual_df.columns for feature in DatasetFields.get_feature_list())\n",
        "\n",
        "    assert all(feature in propaganda_df.columns for feature in DatasetFields.get_feature_list())\n",
        "\n",
        "    return dataset\n",
        "\n",
        "\n",
        "\n",
        "def save_dataset_to_disc(df, filepath):\n",
        "    df.to_csv(filepath, index=False)\n",
        "\n",
        "def generate_dataset(cached_path=None, save_path=None):\n",
        "    '''\n",
        "    Generatest dataset from scracth or uses cached version \n",
        "    \n",
        "    cached_path: str - url of Google Drive file or local disk file\n",
        "    '''\n",
        "    if cached_path is not None:\n",
        "        return get_dataset_from_file(cached_path)\n",
        "\n",
        "    dataset =  generate_dataset_from_subsets()\n",
        "    if save_path is not None:\n",
        "        save_dataset_to_disc(dataset, save_path)\n",
        "\n",
        "    return dataset\n",
        "def get_language_inversed_dataset(subset='train'):\n",
        "    df_ru_factual_filename = 'language_agnostic.csv'\n",
        "\n",
        "    if not os.path.exists(df_ru_factual_filename):\n",
        "        gdown.download(\n",
        "            'https://drive.google.com/uc?id=1cBvXpdWmDWAx1MblWk2C5hwSjoUvu9dm', df_ru_factual_filename)\n",
        "\n",
        "    df_ru_factual_filename = pd.concat([\n",
        "    (\n",
        "    pd.read_csv(df_ru_factual_filename, index_col=0)\n",
        "    .pipe(rename_columns, column_mapping=parser_column_mapping)\n",
        "    .pipe(handle_missing_values)\n",
        "    .pipe(cast_types, column_type_mapping=parser_column_type_mapping)\n",
        "    .pipe(set_label, label=DatasetFields.factual_label)\n",
        "    .pipe(channel_url_to_name)\n",
        "    # .pipe(detect_language_df)\n",
        "         .pipe(set_static_col, DatasetFields.sourced_lang, 'ru')\n",
        "    ),\n",
        "    # to add another dataset include its pipeline\n",
        "    ], axis=0, ignore_index=True)\n",
        "\n",
        "\n",
        "    dataset = pd.concat([\n",
        "    df_ru_factual_filename\n",
        "    ], axis=0, ignore_index=True).sample(frac=1).reset_index(drop=True)\n",
        "    assert all(feature in df_ru_factual_filename.columns for feature in DatasetFields.get_feature_list())\n",
        "\n",
        "    if subset=='train':\n",
        "        return dataset[\n",
        "            dataset['channel'] == 'romanenko_dns'\n",
        "            ]\n",
        "\n",
        "    return dataset[dataset['channel'] == 'inslandd']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXctx18eI4RH"
      },
      "source": [
        "# Visualization utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-22T10:50:49.326258Z",
          "iopub.status.busy": "2024-04-22T10:50:49.325926Z",
          "iopub.status.idle": "2024-04-22T10:50:49.340436Z",
          "shell.execute_reply": "2024-04-22T10:50:49.339552Z",
          "shell.execute_reply.started": "2024-04-22T10:50:49.326222Z"
        },
        "id": "QgMzScGAIOIU",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "colors = { 0: 'g', 1: 'r'}\n",
        "def visualize_channel_distribution(df):\n",
        "    counts_df = df['channel'].value_counts().reset_index()\n",
        "    counts_df.columns = ['channel', 'count']\n",
        "    counts_df['label'] = counts_df['channel'].apply(\n",
        "        lambda name: dataset[dataset['channel'] == name].iloc[0]['label']\n",
        "    )\n",
        "    plt.figure(figsize=(10, 8))\n",
        "\n",
        "    sns.barplot(data=counts_df, x='count', y='channel', hue='label', palette=colors)\n",
        "    plt.tight_layout()\n",
        "    plt.title('Distribution of messages over channel')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-22T10:50:49.342400Z",
          "iopub.status.busy": "2024-04-22T10:50:49.341610Z",
          "iopub.status.idle": "2024-04-22T10:50:49.351211Z",
          "shell.execute_reply": "2024-04-22T10:50:49.350276Z",
          "shell.execute_reply.started": "2024-04-22T10:50:49.342369Z"
        },
        "id": "31WP7O_RQQM4",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def plot_feature_count(df, feature):\n",
        "    plt.figure()\n",
        "    vc = df.groupby(by='label')[feature].value_counts().reset_index()\n",
        "    # vc.columns = [feature, 'count']\n",
        "    sns.barplot(data=vc, hue='label', x=feature, y='count')\n",
        "\n",
        "def plot_feature_by_label(df, feature, title=''):\n",
        "    plt.figure()\n",
        "    labels = df['label'].unique()\n",
        "    label_to_title = DatasetFields.label_title_mapping\n",
        "    label_to_color = DatasetFields.label_to_color\n",
        "    fig, ax = plt.subplots(nrows=1, ncols=len(labels))\n",
        "    colors = {\n",
        "        False: 'y',\n",
        "        True: 'b'\n",
        "    }\n",
        "\n",
        "\n",
        "    for i, l in enumerate(labels):\n",
        "        df_by_label = df[df['label'] == l]\n",
        "        labels_for_pie = df_by_label[feature].value_counts().index\n",
        "        pie_colors = list(map(lambda x: colors[x], labels_for_pie))\n",
        "        ax[i].pie((df_by_label[feature].value_counts().values), labels=labels_for_pie,\n",
        "                  colors=pie_colors)\n",
        "\n",
        "        ax[i].set_title(label_to_title[l])\n",
        "\n",
        "    return fig, ax\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-22T10:50:49.354790Z",
          "iopub.status.busy": "2024-04-22T10:50:49.354453Z",
          "iopub.status.idle": "2024-04-22T10:50:49.363807Z",
          "shell.execute_reply": "2024-04-22T10:50:49.363053Z",
          "shell.execute_reply.started": "2024-04-22T10:50:49.354760Z"
        },
        "executionInfo": {
          "elapsed": 4598,
          "status": "ok",
          "timestamp": 1711466708241,
          "user": {
            "displayName": "Стефан-Юрій Малик",
            "userId": "15188954823949757311"
          },
          "user_tz": -120
        },
        "id": "tjTv0yPYYM3r",
        "outputId": "3c4301dd-025f-466e-f7a5-6b389213fb95",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# # For each label I want to visualize both true and false Ua lang chars\n",
        "# # This in general will allow to understand count in the dataset\n",
        "# sns.countplot(data=dataset, x='label', hue='ua_lang_chars', dodge=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-22T10:50:49.365328Z",
          "iopub.status.busy": "2024-04-22T10:50:49.365014Z",
          "iopub.status.idle": "2024-04-22T10:50:49.372461Z",
          "shell.execute_reply": "2024-04-22T10:50:49.371551Z",
          "shell.execute_reply.started": "2024-04-22T10:50:49.365299Z"
        },
        "executionInfo": {
          "elapsed": 13,
          "status": "ok",
          "timestamp": 1711466708242,
          "user": {
            "displayName": "Стефан-Юрій Малик",
            "userId": "15188954823949757311"
          },
          "user_tz": -120
        },
        "id": "95Zv_6OURjWi",
        "outputId": "72cd6a13-9508-47a8-c85a-a1a80ed3f2ad",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# plot_feature_by_label(dataset, 'ua_lang_chars');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-22T10:50:49.373755Z",
          "iopub.status.busy": "2024-04-22T10:50:49.373484Z",
          "iopub.status.idle": "2024-04-22T10:50:49.380571Z",
          "shell.execute_reply": "2024-04-22T10:50:49.379831Z",
          "shell.execute_reply.started": "2024-04-22T10:50:49.373714Z"
        },
        "executionInfo": {
          "elapsed": 10,
          "status": "ok",
          "timestamp": 1711466708242,
          "user": {
            "displayName": "Стефан-Юрій Малик",
            "userId": "15188954823949757311"
          },
          "user_tz": -120
        },
        "id": "nvb7xru6yDdm",
        "outputId": "5093f1e8-34e9-454d-c258-09d64098918b",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# dataset.groupby(by='label')['ua_lang_chars'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-22T10:50:49.381787Z",
          "iopub.status.busy": "2024-04-22T10:50:49.381514Z",
          "iopub.status.idle": "2024-04-22T10:50:49.389028Z",
          "shell.execute_reply": "2024-04-22T10:50:49.388310Z",
          "shell.execute_reply.started": "2024-04-22T10:50:49.381766Z"
        },
        "executionInfo": {
          "elapsed": 4649,
          "status": "ok",
          "timestamp": 1711466712883,
          "user": {
            "displayName": "Стефан-Юрій Малик",
            "userId": "15188954823949757311"
          },
          "user_tz": -120
        },
        "id": "SpKR31g9P_2f",
        "outputId": "a346e980-70db-4b25-c551-068c738d631f",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# visualize_channel_distribution(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AU06zEqagVQj"
      },
      "source": [
        "# Sampling from the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-22T10:50:49.390256Z",
          "iopub.status.busy": "2024-04-22T10:50:49.390008Z",
          "iopub.status.idle": "2024-04-22T10:50:49.403206Z",
          "shell.execute_reply": "2024-04-22T10:50:49.402434Z",
          "shell.execute_reply.started": "2024-04-22T10:50:49.390236Z"
        },
        "id": "-icc_elhmYNI",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GroupKFold\n",
        "\n",
        "def sample_dataset(df, n=50_000, test_frac=0.125, random_state=42, ignore_groups=False):\n",
        "\n",
        "    df0 = df[df['label'] == 0]\n",
        "    df1 = df[df['label'] == 1]\n",
        "\n",
        "    # Select the same number of labels\n",
        "    '''\n",
        "    TODO: assume there is not enough rows of some label\n",
        "    should we add count to another label so that the total\n",
        "    number of rows is always n?\n",
        "    '''\n",
        "    n0 = min(len(df0), n // 2)\n",
        "    n1 = min(len(df1), n // 2)\n",
        "\n",
        "    print('Sample sizes for label: n0=%s, n1=%s' % (n0, n1))\n",
        "\n",
        "    def channel_stratify_sampling(ldf, label_n):\n",
        "        \"\"\"\n",
        "        Here we want to sample a particular amount\n",
        "        however we want to preserve the distribution\n",
        "        of the channels preserving styles\n",
        "        \"\"\"\n",
        "        res, _ = train_test_split(ldf,\n",
        "                                train_size=label_n,\n",
        "                                shuffle=True,\n",
        "                                stratify=ldf['channel'],\n",
        "                                  random_state=random_state)\n",
        "        return res\n",
        "\n",
        "\n",
        "    df0 = channel_stratify_sampling(df0, n0)\n",
        "    df1 = channel_stratify_sampling(df1, n1)\n",
        "\n",
        "    # This should produce the same results\n",
        "    # GroupKFold is not randomized\n",
        "    n_splits = int(1/test_frac)\n",
        "    if ignore_groups:\n",
        "        cv = KFold(n_splits=n_splits)\n",
        "    else:\n",
        "        cv = GroupKFold(n_splits=n_splits)\n",
        "\n",
        "    train = []\n",
        "    test = []\n",
        "    for it1, it2 in zip(\n",
        "        cv.split(df0, df0['label'], groups=df0['channel']),\n",
        "        cv.split(df1, df1['label'], groups=df1['channel'])\n",
        "    ):\n",
        "        train0, test0 = it1\n",
        "        train1, test1 = it2\n",
        "        train.append(\n",
        "            pd.concat([df0.iloc[train0], df1.iloc[train1]], axis=0,\n",
        "                      ignore_index=True)\n",
        "        )\n",
        "        test.append(\n",
        "            pd.concat([df0.iloc[test0], df1.iloc[test1]], axis=0,\n",
        "                      ignore_index=True)\n",
        "        )\n",
        "        # Since by default we want to return only one split\n",
        "        break\n",
        "\n",
        "    \n",
        "    train =  pd.concat(train)\n",
        "    test = pd.concat(test)\n",
        "    \n",
        "    logger.info(f'Train factual size: {len(train)}')\n",
        "    logger.info(f'Test factual size: {len(test)}')\n",
        "    \n",
        "    return train, test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-22T10:50:49.404662Z",
          "iopub.status.busy": "2024-04-22T10:50:49.404412Z",
          "iopub.status.idle": "2024-04-22T10:50:49.415185Z",
          "shell.execute_reply": "2024-04-22T10:50:49.414246Z",
          "shell.execute_reply.started": "2024-04-22T10:50:49.404641Z"
        },
        "id": "rZPr0qC5IDRl",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def plot_distribution_of_channel2(train, test):\n",
        "\n",
        "    plt.figure(figsize=(10, 10))\n",
        "\n",
        "    plt.subplot(221)\n",
        "    sns.countplot(data=train, y='channel', hue='label')\n",
        "    plt.title('Train set')\n",
        "    plt.yticks(fontsize=8)\n",
        "\n",
        "    plt.subplot(222)\n",
        "    sns.countplot(data=test, y='channel', hue='label')\n",
        "    plt.title('Test set')\n",
        "    plt.yticks(fontsize=8)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    plt.ylabel('Channel')\n",
        "    plt.xlabel('Count')\n",
        "    plt.tight_layout()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-22T10:50:49.416563Z",
          "iopub.status.busy": "2024-04-22T10:50:49.416259Z",
          "iopub.status.idle": "2024-04-22T10:50:49.424186Z",
          "shell.execute_reply": "2024-04-22T10:50:49.423286Z",
          "shell.execute_reply.started": "2024-04-22T10:50:49.416542Z"
        },
        "id": "KO_7dybGFq0o",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# for idx, value in enumerate(zip(X_train, X_test)):\n",
        "#     train, test = value\n",
        "#     print(\"Split #%s\" % idx)\n",
        "#     plot_distribution_of_channel2(train, test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-22T10:50:49.426279Z",
          "iopub.status.busy": "2024-04-22T10:50:49.425637Z",
          "iopub.status.idle": "2024-04-22T10:50:49.436495Z",
          "shell.execute_reply": "2024-04-22T10:50:49.435788Z",
          "shell.execute_reply.started": "2024-04-22T10:50:49.426248Z"
        },
        "id": "1kEWdFwaS_jR",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def plot_distribution_of_channel(x):\n",
        "    assert 'subset' in x.columns\n",
        "\n",
        "    train = x[x['subset'] == 'train']\n",
        "    test = x[x['subset'] == 'test']\n",
        "\n",
        "    plt.figure(figsize=(10, 10))\n",
        "\n",
        "    plt.subplot(221)\n",
        "    sns.countplot(data=train, y='channel')\n",
        "    plt.title('Train set')\n",
        "    plt.yticks(fontsize=8)\n",
        "\n",
        "    plt.subplot(222)\n",
        "    sns.countplot(data=test, y='channel')\n",
        "    plt.title('Test set')\n",
        "    plt.yticks(fontsize=8)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    plt.ylabel('Channel')\n",
        "    plt.xlabel('Count')\n",
        "    plt.tight_layout()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62BsrQoDJMOe"
      },
      "source": [
        "# Training model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-22T10:50:49.438150Z",
          "iopub.status.busy": "2024-04-22T10:50:49.437645Z",
          "iopub.status.idle": "2024-04-22T10:50:49.462724Z",
          "shell.execute_reply": "2024-04-22T10:50:49.462021Z",
          "shell.execute_reply.started": "2024-04-22T10:50:49.438120Z"
        },
        "id": "pxgSTu_uJoVi",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "1. Prepare data. We should have a data loader as a result\n",
        "2. Define the model and stuff\n",
        "3. Test model on the test dataset\n",
        "\n",
        "*somewhere along we way we should put the model onto GPU\n",
        "\n",
        "I want the workflow to look like\n",
        "model, tokenizer = ...\n",
        "data = prepare_data(tokenizer)\n",
        "weights = train_model(model, data)\n",
        "evaluation = evaluate_model(model, some_stuff)\n",
        "\n",
        "\"\"\"\n",
        "import torch\n",
        "\n",
        "import torch.utils.data as D\n",
        "import torch.nn as nn\n",
        "\n",
        "from torch import optim\n",
        "from transformers import AutoModel, AutoTokenizer, \\\n",
        "    AutoModelForSequenceClassification, get_scheduler\n",
        "\n",
        "def get_model_tokenizer_pair(model_name, tokenizer_name=None):\n",
        "    if tokenizer_name is None:\n",
        "        tokenizer_name = model_name\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(model_name,\n",
        "        num_labels=2\n",
        "    )\n",
        "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
        "    return model, tokenizer\n",
        "\n",
        "class PandasDataset(D.Dataset):\n",
        "\n",
        "    def __init__(self, df):\n",
        "        self.df = df\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.df.iloc[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "def get_data_loader(data, batch_size, tokenizer, shuffle=True):\n",
        "    def custom_collate_fn(batch):\n",
        "        \"\"\"\n",
        "        batch is a list of values\n",
        "        in my case possibly a DataFrame\n",
        "        \"\"\"\n",
        "        batch = pd.concat(batch, axis=1).T\n",
        "        labels = torch.Tensor(batch.pop('label').values.astype('int'))\n",
        "        ouput = tokenizer(batch['text'].tolist(), truncation=True,\n",
        "                           padding='max_length', return_tensors='pt')\n",
        "\n",
        "\n",
        "        return (ouput, labels)\n",
        "    assert isinstance(data, pd.DataFrame), 'This code is implemented only to\\\n",
        "    support pd.DataFrame as the input type'\n",
        "    loader = D.DataLoader(PandasDataset(data), batch_size=batch_size,\n",
        "                          shuffle=shuffle,\n",
        "                          collate_fn=custom_collate_fn)\n",
        "    return loader\n",
        "\n",
        "def dict_to_device(dict_, device):\n",
        "    return {k:v.to(device) for k, v in dict_.items()}\n",
        "\n",
        "\n",
        "# def logger(verbose=True):\n",
        "#     def log(epoch, loss, logits, labels):\n",
        "#         f1 = f1_score(torch.argmax(logits, axis=-1).cpu().numpy(),\n",
        "#                       labels.cpu().numpy(),\n",
        "#                       average=None)\n",
        "#         msg =  f'Epoch {epoch}. Loss: {loss}. F1: {f1}'\n",
        "#         if verbose:\n",
        "#             print(msg)\n",
        "\n",
        "#     return log\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "def train_model(model, loader, epochs, device, verbose=None):\n",
        "    # log = logger(verbose=verbose)\n",
        "    optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "    loss_function = nn.CrossEntropyLoss()\n",
        "    num_training_steps = epochs * len(loader)\n",
        "    lr_scheduler = get_scheduler(\n",
        "        name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n",
        "    )\n",
        "    predictions = []\n",
        "    progress_bar = tqdm(range(num_training_steps))\n",
        "    model.train()\n",
        "\n",
        "    # Create the 'checkpoints' folder if it doesn't exist\n",
        "    checkpoints_dir = Path(\"checkpoints\")\n",
        "    checkpoints_dir.mkdir(exist_ok=True)\n",
        "\n",
        "    # Find the latest checkpoint\n",
        "    latest_checkpoint = sorted(checkpoints_dir.glob(\"checkpoint_epoch_*.pth\"), key=os.path.getmtime, reverse=True)\n",
        "    if latest_checkpoint:\n",
        "        latest_checkpoint_path = latest_checkpoint[0]\n",
        "        print(f\"Loading checkpoint from {latest_checkpoint_path}\")\n",
        "        model.load_state_dict(torch.load(latest_checkpoint_path))\n",
        "        start_epoch = int(latest_checkpoint_path.stem.split(\"_\")[-1])\n",
        "    else:\n",
        "        start_epoch = 0\n",
        "\n",
        "    for epoch in range(start_epoch, epochs):\n",
        "        for model_input, labels in loader:\n",
        "            model_input = dict_to_device(model_input, device)\n",
        "            outputs = model(**model_input)\n",
        "            labels = labels.type(torch.LongTensor).to(device)\n",
        "\n",
        "            loss = loss_function(outputs.logits, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            lr_scheduler.step()\n",
        "            optimizer.zero_grad()\n",
        "            progress_bar.update(1)\n",
        "            predictions.append(outputs)\n",
        "\n",
        "            # log(epoch, loss, outputs.logits, labels)\n",
        "\n",
        "        # Save the model checkpoint after each epoch\n",
        "        checkpoint_path = checkpoints_dir / f\"checkpoint_epoch_{epoch}.pth\"\n",
        "        torch.save(model.state_dict(), checkpoint_path)\n",
        "\n",
        "    return model, np.array(predictions)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nx2_Uj2TMnjL"
      },
      "source": [
        "# Testing model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-22T10:50:49.464194Z",
          "iopub.status.busy": "2024-04-22T10:50:49.463931Z",
          "iopub.status.idle": "2024-04-22T10:50:49.471713Z",
          "shell.execute_reply": "2024-04-22T10:50:49.470784Z",
          "shell.execute_reply.started": "2024-04-22T10:50:49.464173Z"
        },
        "id": "XVs6lf08-S5B",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def get_model_score(y_true, y_pred):\n",
        "    f1s = f1_score(y_true, y_pred, average=None)\n",
        "    print(f1s)\n",
        "    return pd.DataFrame({\n",
        "        'f1': f1s\n",
        "    })\n",
        "\n",
        "def evaluate_model(model, loader, device):\n",
        "    model.eval()\n",
        "\n",
        "    # Setup progress bar\n",
        "    n_samples = len(loader)\n",
        "    progress_bar = tqdm(range(n_samples))\n",
        "\n",
        "    y_pred = []\n",
        "    y_true = []\n",
        "\n",
        "\n",
        "    for model_input, labels in loader:\n",
        "        model_input = dict_to_device(model_input, device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**model_input)\n",
        "        # print(outputs.logits)\n",
        "        batch_predictions = torch.argmax(outputs.logits, axis=-1).cpu()\n",
        "        y_pred.extend(batch_predictions.tolist())\n",
        "        y_true.extend(labels.tolist())\n",
        "\n",
        "        progress_bar.update(1)\n",
        "\n",
        "\n",
        "    # print(y_pred)\n",
        "    y_pred = np.array(y_pred, dtype='int')\n",
        "    y_true = np.array(y_true, dtype='int')\n",
        "\n",
        "    return get_model_score(y_true, y_pred), pd.Series(y_pred)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-22T10:50:49.473311Z",
          "iopub.status.busy": "2024-04-22T10:50:49.472969Z",
          "iopub.status.idle": "2024-04-22T10:50:49.483296Z",
          "shell.execute_reply": "2024-04-22T10:50:49.482498Z",
          "shell.execute_reply.started": "2024-04-22T10:50:49.473280Z"
        },
        "id": "vus-yUvVESwz",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def get_bert_score_and_predictions(model, X_test, batch_size = 5):\n",
        "    tokenizer_name = \"google-bert/bert-base-cased\"\n",
        "\n",
        "    # Global config for all the next experiments\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
        "    # We need to not shuffle data while using testing\n",
        "    # for the debugging purposes\n",
        "    test_loader = get_data_loader(X_test, batch_size, tokenizer, shuffle=False)\n",
        "\n",
        "    results = evaluate_model(model, test_loader, device)\n",
        "\n",
        "    return results\n",
        "\n",
        "def get_model_score_and_predictions(model, tokenizer,X_test, batch_size = 8):\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "    test_loader = get_data_loader(X_test, batch_size, tokenizer, shuffle=False)\n",
        "    scores, y_pred = evaluate_model(model, test_loader, device)\n",
        "\n",
        "    return scores, y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-22T10:50:49.484679Z",
          "iopub.status.busy": "2024-04-22T10:50:49.484453Z",
          "iopub.status.idle": "2024-04-22T10:50:49.493413Z",
          "shell.execute_reply": "2024-04-22T10:50:49.492520Z",
          "shell.execute_reply.started": "2024-04-22T10:50:49.484659Z"
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def train_bert(X_train):\n",
        "     # Define config of the experiment\n",
        "    model_name = \"google-bert/bert-base-cased\"\n",
        "    tokenizer_name = \"google-bert/bert-base-cased\"\n",
        "    batch_size = 5\n",
        "    epochs = 3\n",
        "\n",
        "    # Global config for all the next experiments\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "\n",
        "    model, tokenizer = get_model_tokenizer_pair(model_name, tokenizer_name)\n",
        "    model.to(device)\n",
        "\n",
        "    # Get loaders\n",
        "    split = X_train.sample(frac=1)\n",
        "    train_loader = get_data_loader(split, batch_size, tokenizer)\n",
        "\n",
        "    model, preds = train_model(model, train_loader, epochs, device, verbose=False)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-22T10:50:49.494863Z",
          "iopub.status.busy": "2024-04-22T10:50:49.494502Z",
          "iopub.status.idle": "2024-04-22T10:50:49.505713Z",
          "shell.execute_reply": "2024-04-22T10:50:49.504853Z",
          "shell.execute_reply.started": "2024-04-22T10:50:49.494834Z"
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def train_model_by_name(X_train, model_name, tokenizer_name, batch_size=8, epochs=3):\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "    model, tokenizer = get_model_tokenizer_pair(model_name, tokenizer_name)\n",
        "    model.to(device)\n",
        "\n",
        "    # split = X_train.sample(frac=1) # TODO: this sampling is probably redundant\n",
        "    train_loader = get_data_loader(X_train, batch_size, tokenizer)\n",
        "    model, preds = train_model(model, train_loader, epochs, device, verbose=False)\n",
        "\n",
        "    return model, tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_HCFljx-Rch"
      },
      "source": [
        "# Conduct experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-22T10:50:49.506968Z",
          "iopub.status.busy": "2024-04-22T10:50:49.506707Z",
          "iopub.status.idle": "2024-04-22T10:50:49.515406Z",
          "shell.execute_reply": "2024-04-22T10:50:49.514570Z",
          "shell.execute_reply.started": "2024-04-22T10:50:49.506947Z"
        },
        "executionInfo": {
          "elapsed": 1116,
          "status": "ok",
          "timestamp": 1711466714599,
          "user": {
            "displayName": "Стефан-Юрій Малик",
            "userId": "15188954823949757311"
          },
          "user_tz": -120
        },
        "id": "sGchLCuFKnGF",
        "outputId": "319a3841-da4b-430c-a251-ff2b01afcdfd",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "def experiment1():\n",
        "    # At this point we have X_train, X_test\n",
        "\n",
        "    # Define config of the experiment\n",
        "    model_name = \"google-bert/bert-base-cased\"\n",
        "    tokenizer_name = \"google-bert/bert-base-cased\"\n",
        "    batch_size = 5\n",
        "    epochs = 3\n",
        "\n",
        "    # Global config for all the next experiments\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "\n",
        "    model, tokenizer = get_model_tokenizer_pair(model_name, tokenizer_name)\n",
        "    model.to(device)\n",
        "\n",
        "    # Get loaders\n",
        "    split = X_train.sample(frac=1)\n",
        "    train_loader = get_data_loader(split, batch_size, tokenizer)\n",
        "\n",
        "    model, preds = train_model(model, train_loader, epochs, device, verbose=False)\n",
        "\n",
        "    torch.save(model, 'experiment2_model.pkl')\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlxpLz3adLVE"
      },
      "source": [
        "# Translation experiment\n",
        "\n",
        "The previous experiment showed that model trained on the available data cannot generalize well to the selected channel yielding a very poor accuracy.\n",
        "\n",
        "Two problem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-22T10:50:49.516809Z",
          "iopub.status.busy": "2024-04-22T10:50:49.516534Z",
          "iopub.status.idle": "2024-04-22T10:50:49.527576Z",
          "shell.execute_reply": "2024-04-22T10:50:49.526793Z",
          "shell.execute_reply.started": "2024-04-22T10:50:49.516783Z"
        },
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nExperiment - function with a particular name\\n\\n# get data\\n# train model\\n# evaluate model\\n# save dataset and model for the future inference\\n\\nResults:\\n- Train accuracy\\n- Test accuracy\\n- Ru_0 test FP test\\n- Uk_1 test FN test\\n\\n'"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "Experiment - function with a particular name\n",
        "\n",
        "# get data\n",
        "# train model\n",
        "# evaluate model\n",
        "# save dataset and model for the future inference\n",
        "\n",
        "Results:\n",
        "- Train accuracy\n",
        "- Test accuracy\n",
        "- Ru_0 test FP test\n",
        "- Uk_1 test FN test\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-22T10:50:49.528826Z",
          "iopub.status.busy": "2024-04-22T10:50:49.528569Z",
          "iopub.status.idle": "2024-04-22T10:50:49.541191Z",
          "shell.execute_reply": "2024-04-22T10:50:49.540476Z",
          "shell.execute_reply.started": "2024-04-22T10:50:49.528805Z"
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def save_model_and_data_to_folder(model, X_train, X_test, X_test_preds, folder_name, data_path_prefix=''):\n",
        "    \n",
        "    try:\n",
        "        os.mkdir(folder_name)\n",
        "    except: \n",
        "        logger.error('Folder with name {} already exists'.format(folder_name))\n",
        "        \n",
        "    def set_prefix(filename):\n",
        "        if data_path_prefix == '':\n",
        "            return filename\n",
        "        return f'{data_path_prefix}_{filename}'\n",
        "\n",
        "    torch.save(model, os.path.join(folder_name, set_prefix('model.pkl')))\n",
        "    X_train.to_csv(os.path.join(folder_name, set_prefix('X_train.csv')))\n",
        "    X_test.to_csv(os.path.join(folder_name, set_prefix('X_test.csv')))\n",
        "    X_test_preds.to_csv(os.path.join(folder_name, set_prefix('X_test_preds.csv')))\n",
        "    \n",
        "    \n",
        "def save_experiment(model,\n",
        "                    X_train, y_train_preds,\n",
        "                    X_test, y_test_preds,\n",
        "                    X_eval, y_eval_preds,\n",
        "                    folder_name):\n",
        "    try:\n",
        "        os.mkdir(folder_name)\n",
        "    except: \n",
        "        logger.error('Folder with name {} already exists'.format(folder_name))\n",
        "    \n",
        "\n",
        "    torch.save(model, os.path.join(folder_name, 'model.pkl'))\n",
        "    \n",
        "    X_train.to_csv(os.path.join(folder_name, f'X_train.csv'), index=False)\n",
        "    y_train_preds.to_csv(os.path.join(folder_name, f'y_train_preds.csv'), index=False)\n",
        "    X_test.to_csv(os.path.join(folder_name, 'X_test.csv'), index=False)\n",
        "    y_test_preds.to_csv(os.path.join(folder_name, 'y_test_preds.csv'), index=False)\n",
        "    X_eval.to_csv(os.path.join(folder_name, 'X_eval.csv'), index=False)\n",
        "    y_eval_preds.to_csv(os.path.join(folder_name, 'y_eval_preds.csv'), index=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-22T10:50:49.542439Z",
          "iopub.status.busy": "2024-04-22T10:50:49.542185Z",
          "iopub.status.idle": "2024-04-22T10:50:49.550729Z",
          "shell.execute_reply": "2024-04-22T10:50:49.549952Z",
          "shell.execute_reply.started": "2024-04-22T10:50:49.542418Z"
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from functools import wraps\n",
        "\n",
        "def measure_time(func):\n",
        "    '''\n",
        "    Can be used to measure time of individual functions in the notebook\n",
        "    '''\n",
        "    @wraps(func)\n",
        "    def wrapper(*args, **kwargs):\n",
        "        start_time = time()\n",
        "        func(*args, **kwargs)\n",
        "        time_taken = time() - start_time\n",
        "        \n",
        "        print('Execution time {}s'.format(round(time_taken)))\n",
        "        \n",
        "    return wrapper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Scoring helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-22T10:50:49.552378Z",
          "iopub.status.busy": "2024-04-22T10:50:49.551982Z",
          "iopub.status.idle": "2024-04-22T10:50:49.563795Z",
          "shell.execute_reply": "2024-04-22T10:50:49.563038Z",
          "shell.execute_reply.started": "2024-04-22T10:50:49.552349Z"
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def get_score_matrix(\n",
        "    X_train, y_train_preds,\n",
        "    X_test, y_test_preds,\n",
        "    X_eval, y_eval_preds):\n",
        "    \n",
        "    X_train = X_train.assign(\n",
        "        predicted_label=y_train_preds,\n",
        "        subset='train'\n",
        "    )\n",
        "    X_test = X_test.assign(\n",
        "        predicted_label=y_test_preds,\n",
        "        subset='test'\n",
        "    )\n",
        "    X_eval = X_eval.assign(\n",
        "        predicted_label=y_eval_preds,\n",
        "        subset='eval'\n",
        "    )\n",
        "\n",
        "    X = pd.concat([X_train, X_test, X_eval], axis=0).reset_index(drop=True)\n",
        "    X['correct_prediction'] = (X['label'] == X['predicted_label']).astype('int')\n",
        "    scores_table = X.pivot_table('correct_prediction', index=[\n",
        "        'label', DatasetFields.sourced_lang\n",
        "    ],\n",
        "                  columns='subset', aggfunc='mean')\n",
        "    counts_table = X.pivot_table('correct_prediction', index=[\n",
        "        'label', DatasetFields.sourced_lang\n",
        "    ],\n",
        "                  columns='subset', aggfunc='count')\n",
        "    \n",
        "    return scores_table, counts_table\n",
        "    \n",
        "# Testing score matrix\n",
        "def test_score_matrix():\n",
        "    X_train = pd.DataFrame({\n",
        "        'label': np.random.randint(0,2, size=20),\n",
        "        'sourced_lang' : np.random.choice(['ua', 'ru'], size=20)\n",
        "    })\n",
        "    y_train_preds = pd.Series(np.random.randint(0,2, size=20))\n",
        "\n",
        "    return get_score_matrix(X_train, y_train_preds, X_train, y_train_preds, X_train, y_train_preds)\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Experiments\n",
        "\n",
        "In this section experiments are defined. Each experiment is written as a separate function. Each function does not use any global variables to prevent possibility of variable being changed after the initial declaration. \n",
        "\n",
        "When experiment in carried out the results and the data the model was used to train are saved for the purpose of reproductability.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experiment template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-22T10:50:49.572129Z",
          "iopub.status.busy": "2024-04-22T10:50:49.571862Z",
          "iopub.status.idle": "2024-04-22T10:50:49.581560Z",
          "shell.execute_reply": "2024-04-22T10:50:49.580459Z",
          "shell.execute_reply.started": "2024-04-22T10:50:49.572108Z"
        },
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"\\ndef experiment2_1():\\n    '''\\n    Train: cyrilic uk&ru\\n    Test: translated to en\\n    Eval: translated to en\\n\\n    Model: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\\n    '''\\n    # Test configuration\\n    experiment_name = 'experiment2_1'\\n    model_name = 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2'\\n    tokenizer_name = 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2'\\n    batch_size = 8\\n    epochs = 8\\n    \\n    train_n = 20_000\\n    test_n = 4_000\\n    eval_n = 1_000\\n    \\n    translator_batch_size = 8\\n\\n    # Static configuration\\n    sampling_random_state = 42\\n    test_frac = test_n / (train_n + test_n)\\n    device = 'cuda' if torch.cuda.is_available() else 'cpu'\\n\\n    # Generate Train / Test / Eval Datasets\\n    dataset = generate_dataset()\\n    logger.info('fTotal dataset size {len(dataset)}')\\n    X_train, X_test = sample_dataset(dataset,\\n                                     n=train_n + test_n,\\n                                     test_frac=test_frac,\\n                                     random_state=sampling_random_state)\\n    language_inversed = get_language_inversed_dataset(subset='test')\\n    logger.info(f'Eval set size {len(language_inversed)}')\\n    X_eval, _ = train_test_split(language_inversed,\\n                                 train_size=eval_n)\\n\\n    assert 'ua' not in X_eval[DatasetFields.sourced_lang].unique(),         'This test assums that eval set contains only russian language'\\n\\n    # Preprocess dataset\\n    translator = Translator()\\n    X_train = translate_df(X_train, translator.translate, target_lang='en', batch_size=translator_batch_size,\\n                          device=device)\\n    X_test = translate_df(X_test, translator.translate, target_lang='en', batch_size=translator_batch_size,\\n                          device=device)\\n    X_eval = translate_df(X_eval, translator.translate, target_lang='en', batch_size=translator_batch_size,\\n                          device=device)\\n\\n    # Train model\\n    model, tokenizer = train_model_by_name(X_train,\\n                                           model_name=model_name,\\n                                           tokenizer_name=tokenizer_name,\\n                                           batch_size=batch_size,\\n                                           epochs=epochs)\\n    \\n    score_train, _ = get_model_score_and_predictions(\\n        model,\\n        tokenizer,\\n        X_train,\\n        batch_size=batch_size\\n    )\\n\\n    # Score model\\n    score_test, X_test_preds = get_model_score_and_predictions(\\n        model,\\n        tokenizer,\\n        X_test,\\n        batch_size=batch_size\\n    )\\n\\n    score_eval, X_eval_preds = get_model_score_and_predictions(\\n        model, tokenizer, X_eval\\n    )\\n\\n    # Save mdoel\\n    save_model_and_data_to_folder(model,\\n                                  X_train,\\n                                  X_test,\\n                                  X_test_preds,\\n                                  experiment_name)\\n\\n    save_model_and_data_to_folder(model,\\n                                  X_train,\\n                                  X_eval,\\n                                  X_eval_preds,\\n                                  experiment_name,\\n                                  data_path_prefix='eval')\\n\\n    return score_train, score_test, score_eval\\n\""
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "def experiment2_1():\n",
        "    '''\n",
        "    Train: cyrilic uk&ru\n",
        "    Test: translated to en\n",
        "    Eval: translated to en\n",
        "\n",
        "    Model: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\n",
        "    '''\n",
        "    # Test configuration\n",
        "    experiment_name = 'experiment2_1'\n",
        "    model_name = 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2'\n",
        "    tokenizer_name = 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2'\n",
        "    batch_size = 8\n",
        "    epochs = 8\n",
        "    \n",
        "    train_n = 20_000\n",
        "    test_n = 4_000\n",
        "    eval_n = 1_000\n",
        "    \n",
        "    translator_batch_size = 8\n",
        "\n",
        "    # Static configuration\n",
        "    sampling_random_state = 42\n",
        "    test_frac = test_n / (train_n + test_n)\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "    # Generate Train / Test / Eval Datasets\n",
        "    dataset = generate_dataset()\n",
        "    logger.info('fTotal dataset size {len(dataset)}')\n",
        "    X_train, X_test = sample_dataset(dataset,\n",
        "                                     n=train_n + test_n,\n",
        "                                     test_frac=test_frac,\n",
        "                                     random_state=sampling_random_state)\n",
        "    language_inversed = get_language_inversed_dataset(subset='test')\n",
        "    logger.info(f'Eval set size {len(language_inversed)}')\n",
        "    X_eval, _ = train_test_split(language_inversed,\n",
        "                                 train_size=eval_n)\n",
        "\n",
        "    assert 'ua' not in X_eval[DatasetFields.sourced_lang].unique(), \\\n",
        "        'This test assums that eval set contains only russian language'\n",
        "\n",
        "    # Preprocess dataset\n",
        "    translator = Translator()\n",
        "    X_train = translate_df(X_train, translator.translate, target_lang='en', batch_size=translator_batch_size,\n",
        "                          device=device)\n",
        "    X_test = translate_df(X_test, translator.translate, target_lang='en', batch_size=translator_batch_size,\n",
        "                          device=device)\n",
        "    X_eval = translate_df(X_eval, translator.translate, target_lang='en', batch_size=translator_batch_size,\n",
        "                          device=device)\n",
        "\n",
        "    # Train model\n",
        "    model, tokenizer = train_model_by_name(X_train,\n",
        "                                           model_name=model_name,\n",
        "                                           tokenizer_name=tokenizer_name,\n",
        "                                           batch_size=batch_size,\n",
        "                                           epochs=epochs)\n",
        "    \n",
        "    score_train, _ = get_model_score_and_predictions(\n",
        "        model,\n",
        "        tokenizer,\n",
        "        X_train,\n",
        "        batch_size=batch_size\n",
        "    )\n",
        "\n",
        "    # Score model\n",
        "    score_test, X_test_preds = get_model_score_and_predictions(\n",
        "        model,\n",
        "        tokenizer,\n",
        "        X_test,\n",
        "        batch_size=batch_size\n",
        "    )\n",
        "\n",
        "    score_eval, X_eval_preds = get_model_score_and_predictions(\n",
        "        model, tokenizer, X_eval\n",
        "    )\n",
        "\n",
        "    # Save mdoel\n",
        "    save_model_and_data_to_folder(model,\n",
        "                                  X_train,\n",
        "                                  X_test,\n",
        "                                  X_test_preds,\n",
        "                                  experiment_name)\n",
        "\n",
        "    save_model_and_data_to_folder(model,\n",
        "                                  X_train,\n",
        "                                  X_eval,\n",
        "                                  X_eval_preds,\n",
        "                                  experiment_name,\n",
        "                                  data_path_prefix='eval')\n",
        "\n",
        "    return score_train, score_test, score_eval\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experiment 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-22T10:50:49.583090Z",
          "iopub.status.busy": "2024-04-22T10:50:49.582734Z",
          "iopub.status.idle": "2024-04-22T10:50:49.592676Z",
          "shell.execute_reply": "2024-04-22T10:50:49.591910Z",
          "shell.execute_reply.started": "2024-04-22T10:50:49.583060Z"
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def experiment_1():\n",
        "    '''\n",
        "    Train: base dataset\n",
        "    Test: subset\n",
        "    \n",
        "    FP test on ru_0\n",
        "    '''\n",
        "    experiment_name = 'train-test-base'\n",
        "    dataset = generate_dataset()\n",
        "    X_train, X_test = sample_dataset(dataset, \n",
        "                                     n=1000, \n",
        "                                     test_frac=0.2, \n",
        "                                     random_state=42)\n",
        "    \n",
        "    model = train_bert(X_train)\n",
        "    score, X_test_preds = get_bert_score_and_predictions(model, X_test)\n",
        "    save_model_and_data_to_folder(model, \n",
        "                                  X_train, \n",
        "                                  X_test, \n",
        "                                  X_test_preds, \n",
        "                                  experiment_name)\n",
        "    \n",
        "    # Do scoring for FP rate on ru_0 label dataset \n",
        "    X_test_ru_0 = get_language_inversed_dataset(subset='test')\n",
        "    \n",
        "    score_ru_0, X_test_ru_0_preds = get_bert_score_and_predictions(model, X_test_ru_0)\n",
        "    save_model_and_data_to_folder(model, \n",
        "                                  X_train, \n",
        "                                  X_test, \n",
        "                                  X_test_ru_0_preds, \n",
        "                                  experiment_name,\n",
        "                                 data_path_prefix='ru_0')\n",
        "    return score, score_ru_0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-22T10:50:49.594020Z",
          "iopub.status.busy": "2024-04-22T10:50:49.593718Z",
          "iopub.status.idle": "2024-04-22T10:50:49.604822Z",
          "shell.execute_reply": "2024-04-22T10:50:49.603976Z",
          "shell.execute_reply.started": "2024-04-22T10:50:49.593997Z"
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# %time experiment_1()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experiment 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-22T10:50:49.606339Z",
          "iopub.status.busy": "2024-04-22T10:50:49.606044Z",
          "iopub.status.idle": "2024-04-22T10:50:49.616475Z",
          "shell.execute_reply": "2024-04-22T10:50:49.615684Z",
          "shell.execute_reply.started": "2024-04-22T10:50:49.606317Z"
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "class Translator:\n",
        "    def __init__(self):\n",
        "        # Initialize models and tokenizers for each language pair\n",
        "        self.models = {\n",
        "            'ru-en': MarianMTModel.from_pretrained('Helsinki-NLP/opus-mt-ru-en'),\n",
        "            'uk-en': MarianMTModel.from_pretrained('Helsinki-NLP/opus-mt-uk-en'),\n",
        "            'uk-ru': MarianMTModel.from_pretrained('Helsinki-NLP/opus-mt-uk-ru'),\n",
        "            'ru-uk': MarianMTModel.from_pretrained('Helsinki-NLP/opus-mt-ru-uk'),\n",
        "        }\n",
        "        self.tokenizers = {\n",
        "            'ru-en': MarianTokenizer.from_pretrained('Helsinki-NLP/opus-mt-ru-en'),\n",
        "            'uk-en': MarianTokenizer.from_pretrained('Helsinki-NLP/opus-mt-uk-en'),\n",
        "            'uk-ru': MarianTokenizer.from_pretrained('Helsinki-NLP/opus-mt-uk-ru'),\n",
        "            'ru-uk': MarianTokenizer.from_pretrained('Helsinki-NLP/opus-mt-ru-uk'),\n",
        "        }\n",
        "\n",
        "    def translate(self, texts, source_lang, target_lang='en', device='cpu'):\n",
        "        # Validate input is a list\n",
        "        if not isinstance(texts, list):\n",
        "            raise ValueError(\"Texts must be provided as a list of strings.\")\n",
        "        \n",
        "        \n",
        "        # Define the model key based on the source and target language\n",
        "        model_key = f'{source_lang}-{target_lang}'\n",
        "\n",
        "        # Check if the specified model for the language pair is available\n",
        "        if model_key not in self.models:\n",
        "            raise ValueError(f\"Translation model for {model_key} not available.\")\n",
        "        \n",
        "        # Tokenize the text for the source language\n",
        "        tokenizer = self.tokenizers[model_key]\n",
        "        model = self.models[model_key].to(device)\n",
        "        encoded_texts = tokenizer(texts, return_tensors='pt', padding=True, truncation=True).to(device)\n",
        "\n",
        "        # Perform the translation\n",
        "        translated = model.generate(**encoded_texts)\n",
        "\n",
        "        # Decode the translated texts\n",
        "        translated_texts = [tokenizer.decode(t, skip_special_tokens=True) for t in translated]\n",
        "\n",
        "        return translated_texts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-22T10:50:49.617598Z"
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def translate_df(df, translator_func, target_lang='en',batch_size=8, device='cpu'):\n",
        "    source_col = 'text'\n",
        "    lang_col = 'sourced_lang'\n",
        "    \n",
        "    def translate_by_languge(language):\n",
        "        lang_series = df[df[lang_col] == language][source_col]\n",
        "        df.loc[df[lang_col] == language, source_col] = perform_translation(lang_series,\n",
        "                                                               source_lang=language)\n",
        "        return df\n",
        "    \n",
        "    \n",
        "    def perform_translation(series, source_lang):\n",
        "        sentences = series.tolist()\n",
        "        loader = D.DataLoader(sentences, shuffle=False, batch_size=batch_size)\n",
        "        output = []\n",
        "        for s in tqdm(loader):\n",
        "            s_translated = translator_func(s,source_lang=source_lang,\n",
        "                                           target_lang=target_lang,device=device)\n",
        "            output.extend(s_translated)\n",
        "        return output\n",
        "    \n",
        "    \n",
        "    for l in df[lang_col].unique():\n",
        "        # Sometimes we want may want to translate dataset to \n",
        "        # the one of the existing languages \n",
        "        # in such case we just skip all the values\n",
        "        if l == target_lang:\n",
        "            continue\n",
        "        df = translate_by_languge(l)\n",
        "        \n",
        "        \n",
        "    return df\n",
        "    \n",
        "    \n",
        "\n",
        "\n",
        "def experiment_2():\n",
        "    '''\n",
        "    Hypothesis: by translating training and test data before inference\n",
        "    the model should be less language biased and thus perform better on ru_0\n",
        "    test data\n",
        "    '''\n",
        "    experiment_name = 'experiment-2'\n",
        "    dataset = generate_dataset()\n",
        "    X_train, X_test = sample_dataset(dataset, \n",
        "                                     n=1000, \n",
        "                                     test_frac=0.2, \n",
        "                                     random_state=42)\n",
        "    \n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    \n",
        "    # Translate dataset \n",
        "    translator = Translator()\n",
        "    X_train_t = translate_df(X_train, translator.translate, batch_size=9, \n",
        "                            device=device)\n",
        "    X_test_t =  translate_df(X_test, translator.translate, batch_size=9, \n",
        "                            device=device)\n",
        "    \n",
        "    model = train_bert(X_train_t)\n",
        "    score, X_test_preds = get_bert_score_and_predictions(model, X_test_t)\n",
        "    save_model_and_data_to_folder(model, \n",
        "                                  X_train_t, \n",
        "                                  X_test_t, \n",
        "                                  X_test_preds, \n",
        "                                  experiment_name)\n",
        "    \n",
        "    # Do scoring for FP rate on ru_0 label dataset \n",
        "    X_test_ru_0,_ = train_test_split(get_language_inversed_dataset(subset='test'),\n",
        "                                  train_size=300)\n",
        "    \n",
        "    X_test_ru_0_t =  translate_df(X_test_ru_0, translator.translate, batch_size=9, \n",
        "                            device=device)\n",
        "    \n",
        "    score_ru_0, X_test_ru_0_preds = get_bert_score_and_predictions(model, X_test_ru_0_t)\n",
        "    save_model_and_data_to_folder(model, \n",
        "                                  X_train_t, \n",
        "                                  X_test_t, \n",
        "                                  X_test_ru_0_preds, \n",
        "                                  experiment_name,\n",
        "                                 data_path_prefix='ru_0')\n",
        "    return score, score_ru_0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def experiment2_1():\n",
        "    '''\n",
        "    Train: cyrilic uk&ru\n",
        "    Test: translated to en\n",
        "    Eval: translated to en\n",
        "\n",
        "    Model: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\n",
        "    '''\n",
        "    # Test configuration\n",
        "    experiment_name = 'experiment2_1'\n",
        "    model_name = \"google-bert/bert-base-cased\"\n",
        "    tokenizer_name = \"google-bert/bert-base-cased\"\n",
        "    batch_size = 8\n",
        "    epochs = 8\n",
        "    \n",
        "    train_n = 20_000\n",
        "    test_n = 4000\n",
        "    eval_n = 1000\n",
        "    \n",
        "    translator_batch_size = 8\n",
        "\n",
        "    # Static configuration\n",
        "    sampling_random_state = 42\n",
        "    test_frac = test_n / (train_n + test_n)\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "    # Generate Train / Test / Eval Datasets\n",
        "    dataset = generate_dataset()\n",
        "    logger.info('fTotal dataset size {len(dataset)}')\n",
        "    X_train, X_test = sample_dataset(dataset,\n",
        "                                     n=train_n + test_n,\n",
        "                                     test_frac=test_frac,\n",
        "                                     random_state=sampling_random_state)\n",
        "    language_inversed = get_language_inversed_dataset(subset='test')\n",
        "    logger.info(f'Eval set size {len(language_inversed)}')\n",
        "    X_eval, _ = train_test_split(language_inversed,\n",
        "                                 train_size=eval_n)\n",
        "\n",
        "    assert 'ua' not in X_eval[DatasetFields.sourced_lang].unique(), \\\n",
        "        'This test assums that eval set contains only russian language'\n",
        "\n",
        "    # Preprocess dataset\n",
        "    translator = Translator()\n",
        "    X_train = translate_df(X_train, translator.translate, target_lang='en', batch_size=translator_batch_size,\n",
        "                          device=device)\n",
        "    X_test = translate_df(X_test, translator.translate, target_lang='en', batch_size=translator_batch_size,\n",
        "                          device=device)\n",
        "    X_eval = translate_df(X_eval, translator.translate, target_lang='en', batch_size=translator_batch_size,\n",
        "                          device=device)\n",
        "\n",
        "    # Train model\n",
        "    model, tokenizer = train_model_by_name(X_train,\n",
        "                                           model_name=model_name,\n",
        "                                           tokenizer_name=tokenizer_name,\n",
        "                                           batch_size=batch_size,\n",
        "                                           epochs=epochs)\n",
        "    \n",
        "    score_train, X_train_preds = get_model_score_and_predictions(\n",
        "        model,\n",
        "        tokenizer,\n",
        "        X_train,\n",
        "        batch_size=batch_size\n",
        "    )\n",
        "\n",
        "    # Score model\n",
        "    score_test, X_test_preds = get_model_score_and_predictions(\n",
        "        model,\n",
        "        tokenizer,\n",
        "        X_test,\n",
        "        batch_size=batch_size\n",
        "    )\n",
        "\n",
        "    score_eval, X_eval_preds = get_model_score_and_predictions(\n",
        "        model, tokenizer, X_eval\n",
        "    )\n",
        "\n",
        "    # Save mdoel\n",
        "    save_model_and_data_to_folder(model,\n",
        "                                  X_train,\n",
        "                                  X_test,\n",
        "                                  X_test_preds,\n",
        "                                  experiment_name)\n",
        "\n",
        "    save_model_and_data_to_folder(model,\n",
        "                                  X_train,\n",
        "                                  X_eval,\n",
        "                                  X_eval_preds,\n",
        "                                  experiment_name,\n",
        "                                  data_path_prefix='eval')\n",
        "\n",
        "    return score_train, score_test, score_eval, get_score_matrix(\n",
        "        X_train, X_train_preds,\n",
        "        X_test, X_test_preds,\n",
        "        X_eval, X_eval_preds\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# %time experiment_2()\n",
        "\n",
        "# score_train, score_test, score_eval, score_matrix = experiment2_1()\n",
        "# print(score_train)\n",
        "# print(score_test),\n",
        "# print(score_eval)\n",
        "# score_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experiment 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def experiment_3():\n",
        "    '''\n",
        "    Purpose of this test is to perform model training only on russian language\n",
        "    anyways we need to see statistic per language on the model\n",
        "    this task will really show how does the model perform \n",
        "    I wonder if the accuracy on the language inversed dataset will change\n",
        "    '''\n",
        "    \n",
        "    experiment_name = 'experiment-3'\n",
        "    dataset = generate_dataset()\n",
        "    \n",
        "    # Select only russian \n",
        "    lang_mask = dataset[DatasetFields.sourced_lang] == 'ru'\n",
        "    dataset = dataset[lang_mask]\n",
        "    \n",
        "    print(dataset['label'].value_counts())\n",
        "    \n",
        "    X_train, X_test = sample_dataset(dataset, \n",
        "                                     n=1000, \n",
        "                                     test_frac=0.2, \n",
        "                                     random_state=42, ignore_groups=True)\n",
        "    \n",
        "    print('Value counts for train')\n",
        "    print(X_train['label'].value_counts())\n",
        "    print('Value counts for test')\n",
        "    print(X_test['label'].value_counts())\n",
        "    \n",
        "    model = train_bert(X_train)\n",
        "    score, X_test_preds = get_bert_score_and_predictions(model, X_test)\n",
        "    save_model_and_data_to_folder(model, \n",
        "                                  X_train, \n",
        "                                  X_test, \n",
        "                                  X_test_preds, \n",
        "                                  experiment_name)\n",
        "    \n",
        "    # Do scoring for FP rate on ru_0 label dataset \n",
        "    X_test_ru_0 = get_language_inversed_dataset(subset='test')\n",
        "    \n",
        "    score_ru_0, X_test_ru_0_preds = get_bert_score_and_predictions(model, X_test_ru_0)\n",
        "    save_model_and_data_to_folder(model, \n",
        "                                  X_train, \n",
        "                                  X_test, \n",
        "                                  X_test_ru_0_preds, \n",
        "                                  experiment_name,\n",
        "                                 data_path_prefix='ru_0')\n",
        "    return score, score_ru_0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# %time experiment_3()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experiment 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def experiment_4():\n",
        "    '''\n",
        "    Since bleu score for uk-ru translation is higher that uk-en and ru-en \n",
        "    we can translate everything to russian language and compare accuracy\n",
        "    '''\n",
        "    \n",
        "    experiment_name = 'experiment-4-uk-ru-trans'\n",
        "    dataset = generate_dataset()\n",
        "    X_train, X_test = sample_dataset(dataset, \n",
        "                                     n=1000, \n",
        "                                     test_frac=0.2, \n",
        "                                     random_state=42)\n",
        "    \n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    \n",
        "    # Translate dataset \n",
        "    translator = Translator()\n",
        "    X_train_t = translate_df(X_train, translator.translate, target_lang='ru', batch_size=8, \n",
        "                            device=device)\n",
        "    X_test_t =  translate_df(X_test, translator.translate, target_lang='ru', batch_size=8, \n",
        "                            device=device)\n",
        "    \n",
        "    model = train_bert(X_train_t)\n",
        "    score, X_test_preds = get_bert_score_and_predictions(model, X_test_t)\n",
        "    save_model_and_data_to_folder(model, \n",
        "                                  X_train_t, \n",
        "                                  X_test_t, \n",
        "                                  X_test_preds, \n",
        "                                  experiment_name)\n",
        "    \n",
        "    # Do scoring for FP rate on ru_0 label dataset \n",
        "    X_test_ru_0,_ = train_test_split(get_language_inversed_dataset(subset='test'),\n",
        "                                  train_size=300, random_state=42)\n",
        "    \n",
        "    \n",
        "    score_ru_0, X_test_ru_0_preds = get_bert_score_and_predictions(model, X_test_ru_0)\n",
        "    save_model_and_data_to_folder(model, \n",
        "                                  X_train_t, \n",
        "                                  X_test_t, \n",
        "                                  X_test_ru_0_preds, \n",
        "                                  experiment_name,\n",
        "                                 data_path_prefix='ru_0')\n",
        "    return score, score_ru_0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# %time experiment_4()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experiment 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def experiment_5():\n",
        "    '''\n",
        "    Try bert multilangual: train on ru and ua and test on en to avoid for the language bias\n",
        "    '''\n",
        "    # Testing configuration\n",
        "    experiment_name = 'experiment-5'\n",
        "    model_name = 'google-bert/bert-base-multilingual-uncased'\n",
        "    tokenizer_name = 'google-bert/bert-base-multilingual-uncased'\n",
        "    batch_size = 8\n",
        "    epochs = 8\n",
        "    \n",
        "    # Code (may be changed from test to test)\n",
        "    dataset = generate_dataset()\n",
        "    X_train, X_test = sample_dataset(dataset, \n",
        "                                     n=1000, \n",
        "                                     test_frac=0.2, \n",
        "                                     random_state=42)\n",
        "    \n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    \n",
        "    # Translate dataset \n",
        "    translator = Translator()\n",
        "    X_test_t =  translate_df(X_test, translator.translate, target_lang='en', batch_size=9, \n",
        "                            device=device)\n",
        "    \n",
        "\n",
        "    model, tokenizer = train_model_by_name(X_train, \n",
        "                                model_name=model_name, \n",
        "                                tokenizer_name=tokenizer_name, \n",
        "                               batch_size=batch_size,\n",
        "                               epochs=epochs)\n",
        "    score, X_test_preds = get_model_score_and_predictions(model, tokenizer, X_test_t,\n",
        "                                                          batch_size=batch_size)\n",
        "    save_model_and_data_to_folder(model, \n",
        "                                  X_train, \n",
        "                                  X_test_t, \n",
        "                                  X_test_preds, \n",
        "                                  experiment_name)\n",
        "    \n",
        "    # Do scoring for FP rate on ru_0 label dataset \n",
        "    X_test_ru_0,_ = train_test_split(get_language_inversed_dataset(subset='test'),\n",
        "                                  train_size=300)\n",
        "    \n",
        "    X_test_ru_0_t =  translate_df(X_test_ru_0, translator.translate, target_lang='en',\n",
        "                                  batch_size=batch_size, \n",
        "                            device=device)\n",
        "    \n",
        "    score_ru_0, X_test_ru_0_preds = get_model_score_and_predictions(model, tokenizer, X_test_ru_0_t)\n",
        "    save_model_and_data_to_folder(model, \n",
        "                                  X_train, \n",
        "                                  X_test_t, \n",
        "                                  X_test_ru_0_preds, \n",
        "                                  experiment_name,\n",
        "                                 data_path_prefix='ru_0')\n",
        "    return score, score_ru_0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "execution": {
          "iopub.status.idle": "2024-04-22T10:50:49.729630Z",
          "shell.execute_reply": "2024-04-22T10:50:49.728736Z",
          "shell.execute_reply.started": "2024-04-22T10:50:49.718474Z"
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# %time experiment_5()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experiment 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-22T10:50:49.731116Z",
          "iopub.status.busy": "2024-04-22T10:50:49.730841Z",
          "iopub.status.idle": "2024-04-22T10:50:49.742117Z",
          "shell.execute_reply": "2024-04-22T10:50:49.741357Z",
          "shell.execute_reply.started": "2024-04-22T10:50:49.731094Z"
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def experiment_6():\n",
        "    '''\n",
        "    try multilingual bert but train on both ru&uk&en to enchance \n",
        "    score\n",
        "    '''\n",
        "    # Testing configuration\n",
        "    experiment_name = 'experiment-6'\n",
        "    model_name = 'google-bert/bert-base-multilingual-uncased'\n",
        "    tokenizer_name = 'google-bert/bert-base-multilingual-uncased'\n",
        "    batch_size = 8\n",
        "    epochs = 8\n",
        "    \n",
        "    # Code (may be changed from test to test)\n",
        "    dataset = generate_dataset()\n",
        "    X_train, X_test = sample_dataset(dataset, \n",
        "                                     n=1000, \n",
        "                                     test_frac=0.2, \n",
        "                                     random_state=42)\n",
        "    \n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    \n",
        "    # Translate dataset \n",
        "    translator = Translator()\n",
        "    X_test_t =  translate_df(X_test, translator.translate, target_lang='en', batch_size=8, \n",
        "                            device=device)\n",
        "    X_train_t = translate_df(X_train, translator.translate, target_lang='en', batch_size=8, \n",
        "                            device=device)\n",
        "    \n",
        "    # Concat\n",
        "    train_n  = len(X_train)\n",
        "    X_train = pd.concat([X_train, X_train_t], axis='index')\n",
        "    assert train_n  + len(X_train_t) == len(X_train)\n",
        "    \n",
        "\n",
        "    model, tokenizer = train_model_by_name(X_train, \n",
        "                                model_name=model_name, \n",
        "                                tokenizer_name=tokenizer_name, \n",
        "                               batch_size=batch_size,\n",
        "                               epochs=epochs)\n",
        "    score, X_test_preds = get_model_score_and_predictions(model, tokenizer, X_test_t,\n",
        "                                                          batch_size=batch_size)\n",
        "    save_model_and_data_to_folder(model, \n",
        "                                  X_train, \n",
        "                                  X_test_t, \n",
        "                                  X_test_preds, \n",
        "                                  experiment_name)\n",
        "    \n",
        "    # Do scoring for FP rate on ru_0 label dataset \n",
        "    X_test_ru_0,_ = train_test_split(get_language_inversed_dataset(subset='test'),\n",
        "                                  train_size=300)\n",
        "    \n",
        "    X_test_ru_0_t =  translate_df(X_test_ru_0, translator.translate, target_lang='en',\n",
        "                                  batch_size=batch_size, \n",
        "                            device=device)\n",
        "    \n",
        "    score_ru_0, X_test_ru_0_preds = get_model_score_and_predictions(model, tokenizer, X_test_ru_0_t)\n",
        "    save_model_and_data_to_folder(model, \n",
        "                                  X_train, \n",
        "                                  X_test_t, \n",
        "                                  X_test_ru_0_preds, \n",
        "                                  experiment_name,\n",
        "                                 data_path_prefix='ru_0')\n",
        "    return score, score_ru_0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-22T10:50:49.743805Z",
          "iopub.status.busy": "2024-04-22T10:50:49.743262Z",
          "iopub.status.idle": "2024-04-22T10:50:49.754215Z",
          "shell.execute_reply": "2024-04-22T10:50:49.753496Z",
          "shell.execute_reply.started": "2024-04-22T10:50:49.743781Z"
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# %time experiment_6()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experiment 7. All text translated to ru with use of multilangual model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-22T10:50:49.755574Z",
          "iopub.status.busy": "2024-04-22T10:50:49.755269Z",
          "iopub.status.idle": "2024-04-22T10:50:49.764901Z",
          "shell.execute_reply": "2024-04-22T10:50:49.764194Z",
          "shell.execute_reply.started": "2024-04-22T10:50:49.755546Z"
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def experiment7():\n",
        "    '''\n",
        "    Translating ukrainian \n",
        "    '''\n",
        "    # Testing configuration\n",
        "    experiment_name = 'experiment7'\n",
        "    model_name = 'google-bert/bert-base-multilingual-uncased'\n",
        "    tokenizer_name = 'google-bert/bert-base-multilingual-uncased'\n",
        "    batch_size = 8\n",
        "    epochs = 8\n",
        "\n",
        "    # Code (may be changed from test to test)\n",
        "    dataset = generate_dataset()\n",
        "    X_train, X_test = sample_dataset(dataset,\n",
        "                                     n=1000,\n",
        "                                     test_frac=0.2,\n",
        "                                     random_state=42)\n",
        "\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "    # Translate dataset\n",
        "    translator = Translator()\n",
        "    X_train_t = translate_df(X_train, translator.translate, target_lang='ru', batch_size=8,\n",
        "                             device=device)\n",
        "\n",
        "    model, tokenizer = train_model_by_name(X_train_t,\n",
        "                                           model_name=model_name,\n",
        "                                           tokenizer_name=tokenizer_name,\n",
        "                                           batch_size=batch_size,\n",
        "                                           epochs=epochs)\n",
        "    score, X_test_preds = get_model_score_and_predictions(model,\n",
        "                                                          tokenizer,\n",
        "                                                          X_test,\n",
        "                                                          batch_size=batch_size)\n",
        "    save_model_and_data_to_folder(model,\n",
        "                                  X_train_t,\n",
        "                                  X_test,\n",
        "                                  X_test_preds,\n",
        "                                  experiment_name)\n",
        "\n",
        "    # Do scoring for FP rate on ru_0 label dataset\n",
        "    X_test_ru_0, _ = train_test_split(get_language_inversed_dataset(subset='test'),\n",
        "                                      train_size=300)\n",
        "\n",
        "    assert 'ua' not in X_test_ru_0[DatasetFields.sourced_lang].unique(), \\\n",
        "        'This test assums that eval set contains only russian language'\n",
        "\n",
        "    score_ru_0, X_test_ru_0_preds = get_model_score_and_predictions(\n",
        "        model, tokenizer, X_test_ru_0)\n",
        "    save_model_and_data_to_folder(model,\n",
        "                                  X_train,\n",
        "                                  X_test,\n",
        "                                  X_test_ru_0_preds,\n",
        "                                  experiment_name,\n",
        "                                  data_path_prefix='ru_0')\n",
        "    return score, score_ru_0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-22T10:50:49.766141Z",
          "iopub.status.busy": "2024-04-22T10:50:49.765864Z",
          "iopub.status.idle": "2024-04-22T10:50:49.777504Z",
          "shell.execute_reply": "2024-04-22T10:50:49.776798Z",
          "shell.execute_reply.started": "2024-04-22T10:50:49.766119Z"
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# %time experiment7()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experiment 8. Train cyrilic, test en - multilingial model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-22T10:50:49.778722Z",
          "iopub.status.busy": "2024-04-22T10:50:49.778474Z",
          "iopub.status.idle": "2024-04-22T10:50:49.788365Z",
          "shell.execute_reply": "2024-04-22T10:50:49.787616Z",
          "shell.execute_reply.started": "2024-04-22T10:50:49.778693Z"
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def experiment8():\n",
        "    '''\n",
        "    Train: cyrilic uk&ru\n",
        "    Test: translated to en\n",
        "    Eval: translated to en\n",
        "\n",
        "    Model: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\n",
        "    '''\n",
        "    # Test configuration\n",
        "    experiment_name = 'experiment8'\n",
        "    model_name = 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2'\n",
        "    tokenizer_name = 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2'\n",
        "    batch_size = 8\n",
        "    epochs = 8\n",
        "\n",
        "    # Static configuration\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "    # Generate Train / Test / Eval Datasets\n",
        "    dataset = generate_dataset()\n",
        "    X_train, X_test = sample_dataset(dataset,\n",
        "                                     n=1000,\n",
        "                                     test_frac=0.2,\n",
        "                                     random_state=42)\n",
        "    X_eval, _ = train_test_split(get_language_inversed_dataset(subset='test'),\n",
        "                                 train_size=300)\n",
        "\n",
        "    assert 'ua' not in X_eval[DatasetFields.sourced_lang].unique(), \\\n",
        "        'This test assums that eval set contains only russian language'\n",
        "\n",
        "    # Preprocess dataset\n",
        "    translator = Translator()\n",
        "    X_test = translate_df(X_test, translator.translate, target_lang='en', batch_size=8,\n",
        "                          device=device)\n",
        "\n",
        "    # Train model\n",
        "    model, tokenizer = train_model_by_name(X_train,\n",
        "                                           model_name=model_name,\n",
        "                                           tokenizer_name=tokenizer_name,\n",
        "                                           batch_size=batch_size,\n",
        "                                           epochs=epochs)\n",
        "\n",
        "    # Score model\n",
        "    score_test, X_test_preds = get_model_score_and_predictions(\n",
        "        model,\n",
        "        tokenizer,\n",
        "        X_test,\n",
        "        batch_size=batch_size\n",
        "    )\n",
        "\n",
        "    score_eval, X_eval_preds = get_model_score_and_predictions(\n",
        "        model, tokenizer, X_eval\n",
        "    )\n",
        "\n",
        "    # Save mdoel\n",
        "    save_model_and_data_to_folder(model,\n",
        "                                  X_train,\n",
        "                                  X_test,\n",
        "                                  X_test_preds,\n",
        "                                  experiment_name)\n",
        "\n",
        "    save_model_and_data_to_folder(model,\n",
        "                                  X_train,\n",
        "                                  X_eval,\n",
        "                                  X_eval_preds,\n",
        "                                  experiment_name,\n",
        "                                  data_path_prefix='eval')\n",
        "\n",
        "    return score_test, score_eval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-22T10:50:49.789791Z",
          "iopub.status.busy": "2024-04-22T10:50:49.789498Z",
          "iopub.status.idle": "2024-04-22T10:50:49.801644Z",
          "shell.execute_reply": "2024-04-22T10:50:49.800915Z",
          "shell.execute_reply.started": "2024-04-22T10:50:49.789769Z"
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# %time experiment8()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experiment 9. Train only ru subset, test only ru subset, eval only ru subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-22T10:50:49.803048Z",
          "iopub.status.busy": "2024-04-22T10:50:49.802758Z",
          "iopub.status.idle": "2024-04-22T10:50:49.813619Z",
          "shell.execute_reply": "2024-04-22T10:50:49.812898Z",
          "shell.execute_reply.started": "2024-04-22T10:50:49.803016Z"
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def experiment9():\n",
        "    '''\n",
        "\n",
        "    '''\n",
        "    # Test configuration\n",
        "    experiment_name = 'experiment8'\n",
        "    model_name = 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2'\n",
        "    tokenizer_name = 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2'\n",
        "    batch_size = 8\n",
        "    epochs = 8\n",
        "\n",
        "    # Static configuration\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "    # Generate Train / Test / Eval Datasets\n",
        "    dataset = generate_dataset()\n",
        "    dataset = dataset[dataset[DatasetFields.sourced_lang] == 'ru']\n",
        "    X_train, X_test = sample_dataset(dataset,\n",
        "                                     n=1000,\n",
        "                                     test_frac=0.2,\n",
        "                                     random_state=42)\n",
        "    \n",
        "    lang_inversed_dataset = get_language_inversed_dataset(subset='test')\n",
        "    lang_inversed_dataset = lang_inversed_dataset[\n",
        "        lang_inversed_dataset[DatasetFields.sourced_lang] == 'ru'\n",
        "    ]\n",
        "    X_eval, _ = train_test_split(lang_inversed_dataset,\n",
        "                                 train_size=300)\n",
        "    \n",
        "\n",
        "    assert 'ua' not in X_eval[DatasetFields.sourced_lang].unique(), \\\n",
        "        'This test assums that eval set contains only russian language'\n",
        "\n",
        "    # Preprocess dataset\n",
        "    \n",
        "\n",
        "    # Train model\n",
        "    model, tokenizer = train_model_by_name(X_train,\n",
        "                                           model_name=model_name,\n",
        "                                           tokenizer_name=tokenizer_name,\n",
        "                                           batch_size=batch_size,\n",
        "                                           epochs=epochs)\n",
        "\n",
        "    # Score model\n",
        "    score_test, X_test_preds = get_model_score_and_predictions(\n",
        "        model,\n",
        "        tokenizer,\n",
        "        X_test,\n",
        "        batch_size=batch_size\n",
        "    )\n",
        "\n",
        "    score_eval, X_eval_preds = get_model_score_and_predictions(\n",
        "        model, tokenizer, X_eval\n",
        "    )\n",
        "\n",
        "    # Save mdoel\n",
        "    save_model_and_data_to_folder(model,\n",
        "                                  X_train,\n",
        "                                  X_test,\n",
        "                                  X_test_preds,\n",
        "                                  experiment_name)\n",
        "\n",
        "    save_model_and_data_to_folder(model,\n",
        "                                  X_train,\n",
        "                                  X_eval,\n",
        "                                  X_eval_preds,\n",
        "                                  experiment_name,\n",
        "                                  data_path_prefix='eval')\n",
        "\n",
        "    return score_test, score_eval\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-22T10:50:49.814839Z",
          "iopub.status.busy": "2024-04-22T10:50:49.814570Z",
          "iopub.status.idle": "2024-04-22T10:50:49.826324Z",
          "shell.execute_reply": "2024-04-22T10:50:49.825575Z",
          "shell.execute_reply.started": "2024-04-22T10:50:49.814816Z"
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# %time experiment9()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experiment 10\n",
        "\n",
        "Experiment 10.\n",
        "Use multilangual model. Perform train on uk&ru. Test on uk&ru. Eval on ru_0 + ru_uk_1\n",
        "Motivation: we didn't test multilangual model and it may be less prone for overfitting on the language features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-22T10:50:49.827653Z",
          "iopub.status.busy": "2024-04-22T10:50:49.827403Z",
          "iopub.status.idle": "2024-04-22T10:50:49.840183Z",
          "shell.execute_reply": "2024-04-22T10:50:49.839350Z",
          "shell.execute_reply.started": "2024-04-22T10:50:49.827631Z"
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def experiment10():\n",
        "    '''\n",
        "    '''\n",
        "    # Test configuration\n",
        "    experiment_name = 'experiment10'\n",
        "    model_name = 'google-bert/bert-base-multilingual-uncased'\n",
        "    tokenizer_name = 'google-bert/bert-base-multilingual-uncased'\n",
        "    batch_size = 8\n",
        "    epochs = 8\n",
        "    \n",
        "    train_n = 1000\n",
        "    test_n = 200\n",
        "    eval_n = 200\n",
        "    \n",
        "    translator_batch_size = 8\n",
        "\n",
        "    # Static configuration\n",
        "    sampling_random_state = 42\n",
        "    test_frac = test_n / (train_n + test_n)\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "    # Generate Train / Test / Eval Datasets\n",
        "    dataset = generate_dataset()\n",
        "    logger.info('fTotal dataset size {len(dataset)}')\n",
        "    X_train, X_test = sample_dataset(dataset,\n",
        "                                     n=train_n + test_n,\n",
        "                                     test_frac=test_frac,\n",
        "                                     random_state=sampling_random_state)\n",
        "    language_inversed = get_language_inversed_dataset(subset='test')\n",
        "    logger.info(f'Eval set size {len(language_inversed)}')\n",
        "    X_eval, _ = train_test_split(language_inversed,\n",
        "                                 train_size=eval_n)\n",
        "\n",
        "    assert 'ua' not in X_eval[DatasetFields.sourced_lang].unique(), \\\n",
        "        'This test assums that eval set contains only russian language'\n",
        "\n",
        "    # Preprocess dataset\n",
        "    translator = Translator()\n",
        "    # Create uk_1 dataset\n",
        "    ru_1 = X_test[\n",
        "        (X_test[DatasetFields.sourced_lang] == 'ru') & \\\n",
        "            (X_test[DatasetFields.label]  == 1)]\n",
        "    uk_1 = translate_df(ru_1, translator.translate, target_lang='uk', batch_size=translator_batch_size,\n",
        "                          device=device)\n",
        "    uk_1[DatasetFields.sourced_lang] = 'ua'\n",
        "    X_eval = pd.concat([uk_1, X_eval]).sample(frac=1)\n",
        "    # Train model\n",
        "    model, tokenizer = train_model_by_name(X_train,\n",
        "                                           model_name=model_name,\n",
        "                                           tokenizer_name=tokenizer_name,\n",
        "                                           batch_size=batch_size,\n",
        "                                           epochs=epochs)\n",
        "    \n",
        "    score_train, X_train_preds = get_model_score_and_predictions(\n",
        "        model,\n",
        "        tokenizer,\n",
        "        X_train,\n",
        "        batch_size=batch_size\n",
        "    )\n",
        "\n",
        "    # Score model\n",
        "    score_test, X_test_preds = get_model_score_and_predictions(\n",
        "        model,\n",
        "        tokenizer,\n",
        "        X_test,\n",
        "        batch_size=batch_size\n",
        "    )\n",
        "\n",
        "    score_eval, X_eval_preds = get_model_score_and_predictions(\n",
        "        model, tokenizer, X_eval\n",
        "    )\n",
        "\n",
        "    # Save mdoel\n",
        "    save_model_and_data_to_folder(model,\n",
        "                                  X_train,\n",
        "                                  X_test,\n",
        "                                  X_test_preds,\n",
        "                                  experiment_name)\n",
        "\n",
        "    save_model_and_data_to_folder(model,\n",
        "                                  X_train,\n",
        "                                  X_eval,\n",
        "                                  X_eval_preds,\n",
        "                                  experiment_name,\n",
        "                                  data_path_prefix='eval')\n",
        "\n",
        "    return score_train, score_test, score_eval, get_score_matrix(\n",
        "        X_train, X_train_preds,\n",
        "        X_test, X_test_preds,\n",
        "        X_eval, X_eval_preds\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-22T10:50:49.841613Z",
          "iopub.status.busy": "2024-04-22T10:50:49.841308Z",
          "iopub.status.idle": "2024-04-22T10:50:49.852350Z",
          "shell.execute_reply": "2024-04-22T10:50:49.851560Z",
          "shell.execute_reply.started": "2024-04-22T10:50:49.841582Z"
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# experiment10()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experiment 11\n",
        "Use multilangual model. Perform train on uk&ru. Add to train set unseen russian propaganda but translated to uk."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-22T10:50:49.853715Z",
          "iopub.status.busy": "2024-04-22T10:50:49.853451Z",
          "iopub.status.idle": "2024-04-22T10:50:49.867780Z",
          "shell.execute_reply": "2024-04-22T10:50:49.866967Z",
          "shell.execute_reply.started": "2024-04-22T10:50:49.853694Z"
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def experiment11():\n",
        "    '''\n",
        "    Train: cyrilic uk&ru\n",
        "    Test: translated to en\n",
        "    Eval: translated to en\n",
        "\n",
        "    Model: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\n",
        "    '''\n",
        "    # Test configuration\n",
        "    experiment_name = 'experiment11'\n",
        "    model_name = 'google-bert/bert-base-multilingual-uncased'\n",
        "    tokenizer_name = 'google-bert/bert-base-multilingual-uncased'\n",
        "    batch_size = 8\n",
        "    epochs = 8\n",
        "    \n",
        "    train_n = 2000\n",
        "    test_n = 200\n",
        "    eval_n = 200\n",
        "    \n",
        "    translator_batch_size = 8\n",
        "\n",
        "    # Static configuration\n",
        "    sampling_random_state = 42\n",
        "    test_frac = test_n / (train_n + test_n)\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "    # Generate Train / Test / Eval Datasets\n",
        "    dataset = generate_dataset()\n",
        "    logger.info('fTotal dataset size {len(dataset)}')\n",
        "    X_train, X_test = sample_dataset(dataset,\n",
        "                                     n=train_n + test_n,\n",
        "                                     test_frac=test_frac,\n",
        "                                     random_state=sampling_random_state)\n",
        "    language_inversed = get_language_inversed_dataset(subset='test')\n",
        "    logger.info(f'Eval set size {len(language_inversed)}')\n",
        "    X_eval, _ = train_test_split(language_inversed,\n",
        "                                 train_size=eval_n)\n",
        "\n",
        "    assert 'ua' not in X_eval[DatasetFields.sourced_lang].unique(), \\\n",
        "        'This test assums that eval set contains only russian language'\n",
        "\n",
        "    # Preprocess dataset\n",
        "    translator = Translator()\n",
        "    # Add uk_1 to train dataset\n",
        "    \n",
        "    X_train_ru_1 = X_train[\n",
        "        X_train[(DatasetFields.sourced_lang == 'ru') & \\\n",
        "            (DatasetFields.label == 1)]]\n",
        "    \n",
        "    selected_ru_1 = X_train_ru_1.sample(frac=0.1)\n",
        "    X_train = X_train.drop(index=selected_ru_1.index)\n",
        "\n",
        "    \n",
        "    X_train_uk_1 = translate_df(selected_ru_1, translator.translate, target_lang='uk', batch_size=translator_batch_size,\n",
        "                          device=device)\n",
        "    X_train = pd.concat([X_train_uk_1, X_train]).sample(frac=1)\n",
        "    \n",
        "    \n",
        "    # Create uk_1 eval dataset\n",
        "    ru_1 = X_test[X_test[(DatasetFields.sourced_lang == 'ru') & (DatasetFields.label == 1)]]\n",
        "    uk_1 = translate_df(ru_1, translator.translate, target_lang='uk', batch_size=translator_batch_size,\n",
        "                          device=device)\n",
        "    X_eval = pd.concat([uk_1, X_eval]).sample(frac=1)\n",
        "    # Train model\n",
        "    model, tokenizer = train_model_by_name(X_train,\n",
        "                                           model_name=model_name,\n",
        "                                           tokenizer_name=tokenizer_name,\n",
        "                                           batch_size=batch_size,\n",
        "                                           epochs=epochs)\n",
        "    \n",
        "    score_train, X_train_preds = get_model_score_and_predictions(\n",
        "        model,\n",
        "        tokenizer,\n",
        "        X_train,\n",
        "        batch_size=batch_size\n",
        "    )\n",
        "\n",
        "    # Score model\n",
        "    score_test, X_test_preds = get_model_score_and_predictions(\n",
        "        model,\n",
        "        tokenizer,\n",
        "        X_test,\n",
        "        batch_size=batch_size\n",
        "    )\n",
        "\n",
        "    score_eval, X_eval_preds = get_model_score_and_predictions(\n",
        "        model, tokenizer, X_eval\n",
        "    )\n",
        "\n",
        "    # Save mdoel\n",
        "    save_model_and_data_to_folder(model,\n",
        "                                  X_train,\n",
        "                                  X_test,\n",
        "                                  X_test_preds,\n",
        "                                  experiment_name)\n",
        "\n",
        "    save_model_and_data_to_folder(model,\n",
        "                                  X_train,\n",
        "                                  X_eval,\n",
        "                                  X_eval_preds,\n",
        "                                  experiment_name,\n",
        "                                  data_path_prefix='eval')\n",
        "\n",
        "    return score_train, score_test, score_eval, get_score_matrix(\n",
        "        X_train, X_train_preds,\n",
        "        X_test, X_test_preds,\n",
        "        X_eval, X_eval_preds\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Experiments features in the diploma thesis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-22T10:50:49.869608Z",
          "iopub.status.busy": "2024-04-22T10:50:49.869132Z",
          "iopub.status.idle": "2024-04-22T10:50:49.891254Z",
          "shell.execute_reply": "2024-04-22T10:50:49.890430Z",
          "shell.execute_reply.started": "2024-04-22T10:50:49.869585Z"
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "metrics = {\n",
        "    'f1': partial(f1_score, average=None),\n",
        "    'precision': partial(precision_score, average=None),\n",
        "    'recall' : partial(recall_score, average=None),\n",
        "    'count': lambda x,y: [np.sum((x==i).astype(int)).astype(int) for i in x]\n",
        "}\n",
        "def plot_messages_by_date(inference_df, use_weekly_ticks=True,**kwargs):\n",
        "    g = sns.catplot(x='date-only', kind='count', data=inference_df, col='channel', col_wrap=2,  **kwargs)\n",
        "    \n",
        "    if use_weekly_ticks:\n",
        "        for ax in g.axes.flat:\n",
        "            ticks = ax.get_xticks()\n",
        "            tick_dates = pd.date_range(\n",
        "                inference_df['date-only'].min(), \n",
        "            inference_df['date-only'].max(), freq='W')\n",
        "            tick_labels = []\n",
        "            for i, value in enumerate(ticks):\n",
        "                if i % 7 == 0:\n",
        "                    tick_labels.append(tick_dates.date[i // 7])\n",
        "                else:\n",
        "                    tick_labels.append('')\n",
        "\n",
        "            ax.set_xticklabels(tick_labels, rotation=45)\n",
        "\n",
        "    plt.subplots_adjust(top=0.8)\n",
        "def uniform_date_sample(x, sample_size):\n",
        "    sample_size = min(len(x) - 1, sample_size)\n",
        "    return x.sample(sample_size, random_state=42)\n",
        "    \n",
        "    # I wanted to sample the messages according to the\n",
        "    # amount of messages sent in the day\n",
        "    # since if there are peek days - important events occur\n",
        "    # and narratives may change\n",
        "    counts = x['date-only'].value_counts().sort_index()\n",
        "    for i in range(len(caunts)):\n",
        "        data = counts.iloc[i]\n",
        "        if data == 1:\n",
        "            if i < len(counts) - 1:\n",
        "                # add to forward\n",
        "                counts.iloc[i+1] += 1\n",
        "                x.loc[x['date-only'] == counts.index[i],'date-only'] = counts.index[i + 1]\n",
        "            else:\n",
        "                # add backward\n",
        "                counts.iloc[i-1] += 1\n",
        "                x.loc[x['date-only'] == counts.index[i],'date-only'] = counts.index[i - 1]\n",
        "                 \n",
        "    return train_test_split(x, train_size=sample_size, stratify=x['date-only'], random_state=42)[0]\n",
        "def calculate_time_dynamics(story_df, start_date, end_date, model, tokenizer, batch_size, device='cuda'):\n",
        "    inference_df = story_df.loc[start_date:end_date].reset_index('date')\n",
        "    inference_df['date-only'] = inference_df['date'].dt.date\n",
        "    sampled_inf_df = inference_df.groupby('channel').apply(\n",
        "    partial(uniform_date_sample, sample_size=200)).reset_index(drop=True)\n",
        "    \n",
        "    sampled_inf_df['original_text'] = sampled_inf_df['text']\n",
        "    translator = Translator()\n",
        "\n",
        "\n",
        "    _, inference_df_en_preds = get_model_score_and_predictions(\n",
        "        model,\n",
        "        tokenizer,\n",
        "        sampled_inf_df,\n",
        "        # translate_df(sampled_inf_df,translator.translate, target_lang='en', device=device, batch_size=batch_size),\n",
        "        batch_size=batch_size\n",
        "    )\n",
        "    \n",
        "    return sampled_inf_df.reset_index(drop=True).assign(\n",
        "        predicted_label=inference_df_en_preds\n",
        "    )\n",
        "def sample_tp_fn(x, sample_size):\n",
        "    pd.set_option('display.max_colwidth', 0)\n",
        "    x['true_prediction'] = x['label'] == x['predicted_label']\n",
        "    return x.groupby('true_prediction').apply(lambda i: i.sample(sample_size, random_state=43))    \n",
        "def result_matrix(X, groupby, metrics, use_subsets=False):\n",
        "    \n",
        "    def computer_metric_on_group(df):\n",
        "        names = []\n",
        "        computed_metrics = defaultdict(list)\n",
        "        for name, f in metrics.items():\n",
        "            names.append(name)\n",
        "            metrics_for_each_label = f(df.iloc[:, 0], df.iloc[:, 1])\n",
        "            for label, value in enumerate(metrics_for_each_label):\n",
        "                computed_metrics[label].append(value)\n",
        "        res =  pd.DataFrame({\n",
        "            key: computed_metrics[key] for index, key in enumerate(df.iloc[:, 0].unique())\n",
        "        }, index=names).T\n",
        "        res.index.name = 'label'\n",
        "        return res\n",
        "\n",
        "    if use_subsets:\n",
        "        return X.groupby(['subset'] + groupby)[['label', 'predicted_label']].apply(computer_metric_on_group\n",
        "    ).sort_index(axis=1).unstack('subset').sort_index(axis=1, level=[0,1], ascending=[False, False])\n",
        "\n",
        "    return X.groupby(groupby)[['label', 'predicted_label']].apply(computer_metric_on_group\n",
        "    ).sort_index(axis=1).sort_index(axis=1, level=0, ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experiment 12\n",
        "\n",
        "The problem is that only a few of ru 0 instances were included in the set. Therefore model performs poorly on ru_0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-22T10:50:49.892861Z",
          "iopub.status.busy": "2024-04-22T10:50:49.892538Z",
          "iopub.status.idle": "2024-04-22T10:50:49.905328Z",
          "shell.execute_reply": "2024-04-22T10:50:49.904481Z",
          "shell.execute_reply.started": "2024-04-22T10:50:49.892830Z"
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from itertools import product\n",
        "def stratified_sampling(df, columns_to_group, column_to_stratify, n, random_state):\n",
        "    '''\n",
        "    Given the list of columns sample in a way so that each class\n",
        "    has an even number of samples\n",
        "\n",
        "    Given columns I should determine a list of unique values and get\n",
        "    a cartesian product\n",
        "    after that divide n by the number of classes\n",
        "    I given these\n",
        "    '''\n",
        "\n",
        "    # Determine how much classes we have\n",
        "    unique_values = [df[column].unique().tolist() for column in columns_to_group]\n",
        "    index = list(product(*unique_values))\n",
        "    n_of_grouped_features = len(index)\n",
        "    n_per_feature = n // n_of_grouped_features\n",
        "\n",
        "    result_df = pd.DataFrame()\n",
        "    for i, columns_to_group_values in enumerate(index):\n",
        "        n_per_feature = (n - len(result_df)) // (n_of_grouped_features - i)\n",
        "        mask = np.ones((len(df),), dtype='bool')\n",
        "        \n",
        "        for column, value in zip(columns_to_group, columns_to_group_values):\n",
        "            mask &= df[column] == value\n",
        "\n",
        "        group_rows = df[mask]\n",
        "#         print(f'Group: {columns_to_group_values}, Size: {len(group_rows)}')\n",
        "        if len(group_rows) > n_per_feature:\n",
        "\n",
        "                \n",
        "            # collapse classes until for those with values less than 1\n",
        "            channel_text_count = \\\n",
        "            df[mask][column_to_stratify].value_counts(ascending=True)\n",
        "            channels_to_unite = channel_text_count[channel_text_count == 1].index\n",
        "            \n",
        "            group_rows.loc[group_rows[column_to_stratify].isin(channels_to_unite), \n",
        "                       column_to_stratify] = '<united>'\n",
        "            \n",
        "            if len(group_rows[column_to_stratify].unique()) < 2:\n",
        "                stratify_condition = None\n",
        "            else:\n",
        "                stratify_condition = group_rows[column_to_stratify]\n",
        "\n",
        "#             print(group_rows[column_to_stratify].value_counts(ascending=True))\n",
        "            '''The least number of groups for any class should be 2'''\n",
        "            sampled_group,_ = train_test_split(group_rows,\n",
        "                            stratify=stratify_condition,\n",
        "                            train_size=n_per_feature, random_state=random_state)\n",
        "        else:\n",
        "            sampled_group = group_rows\n",
        "\n",
        "        result_df = pd.concat([result_df, sampled_group])\n",
        "        \n",
        "\n",
        "    return result_df.sample(frac=1, random_state=random_state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-22T10:50:49.907006Z",
          "iopub.status.busy": "2024-04-22T10:50:49.906520Z",
          "iopub.status.idle": "2024-04-22T10:50:49.922183Z",
          "shell.execute_reply": "2024-04-22T10:50:49.921260Z",
          "shell.execute_reply.started": "2024-04-22T10:50:49.906965Z"
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def get_train_test_eval_from_dataset(dataset, X_train_n, X_test_n, X_eval_n,\n",
        "                                     random_state, debug=False):\n",
        "    train_test_eval = stratified_sampling(dataset,\n",
        "                                          [DatasetFields.label,\n",
        "                                              DatasetFields.sourced_lang],\n",
        "                                          'channel',\n",
        "                                          n=X_train_n + X_test_n + X_eval_n,\n",
        "                                          random_state=random_state)\n",
        "\n",
        "    test_eval = stratified_sampling(train_test_eval,\n",
        "                                    [DatasetFields.label,\n",
        "                                        DatasetFields.sourced_lang],\n",
        "                                    'channel',\n",
        "                                    n=X_test_n + X_eval_n,\n",
        "                                    random_state=random_state)\n",
        "    X_train = train_test_eval.drop(index=test_eval.index)\n",
        "    X_eval = stratified_sampling(test_eval,\n",
        "                                 [DatasetFields.label, DatasetFields.sourced_lang],\n",
        "                                 'channel',\n",
        "                                 n=X_eval_n,\n",
        "                                 random_state=random_state)\n",
        "    X_test = test_eval.drop(index=X_eval.index)\n",
        "\n",
        "    if debug:\n",
        "        return pd.concat([\n",
        "            X_train.assign(subset='train'),\n",
        "            X_test.assign(subset='test'),\n",
        "            X_eval.assign(subset='eval')\n",
        "        ]).pivot_table('text',\n",
        "                       index=[DatasetFields.label,\n",
        "                              DatasetFields.sourced_lang, DatasetFields.channel],\n",
        "                       columns='subset', aggfunc='count')\n",
        "\n",
        "    return X_train, X_test, X_eval\n",
        "\n",
        "\n",
        "def experiment12():\n",
        "    '''\n",
        "    Train: cyrilic uk&ru\n",
        "    Test: translated to en\n",
        "    Eval: translated to en\n",
        "\n",
        "    Model: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\n",
        "    '''\n",
        "    # Test configuration\n",
        "    X_train_n = 80000\n",
        "    X_test_n = 10000\n",
        "    X_eval_n = 10000\n",
        "    \n",
        "    sampling_random_state = 42\n",
        "    experiment_name = 'experiment2_1'\n",
        "    model_name = \"google-bert/bert-base-cased\"\n",
        "    tokenizer_name = \"google-bert/bert-base-cased\"\n",
        "    batch_size = 8\n",
        "    epochs = 8\n",
        "\n",
        "    translator_batch_size = 8\n",
        "    \n",
        "    dataset = generate_dataset()\n",
        "    X_train, X_test, X_eval = get_train_test_eval_from_dataset(\n",
        "        dataset,\n",
        "        X_train_n,\n",
        "        X_test_n,\n",
        "        X_eval_n,\n",
        "        random_state=sampling_random_state)\n",
        "\n",
        "    # Static configuration\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "\n",
        "    # Preprocess dataset\n",
        "    translator = Translator()\n",
        "    X_train = translate_df(X_train, translator.translate, target_lang='en', batch_size=translator_batch_size,\n",
        "                           device=device)\n",
        "    X_test = translate_df(X_test, translator.translate, target_lang='en', batch_size=translator_batch_size,\n",
        "                          device=device)\n",
        "    X_eval = translate_df(X_eval, translator.translate, target_lang='en', batch_size=translator_batch_size,\n",
        "                          device=device)\n",
        "\n",
        "    # Train model\n",
        "    model, tokenizer = train_model_by_name(X_train,\n",
        "                                           model_name=model_name,\n",
        "                                           tokenizer_name=tokenizer_name,\n",
        "                                           batch_size=batch_size,\n",
        "                                           epochs=epochs)\n",
        "\n",
        "    # Score model\n",
        "    score_train, X_train_preds = get_model_score_and_predictions(\n",
        "        model,\n",
        "        tokenizer,\n",
        "        X_train,\n",
        "        batch_size=batch_size\n",
        "    )\n",
        "\n",
        "    \n",
        "    score_test, X_test_preds = get_model_score_and_predictions(\n",
        "        model,\n",
        "        tokenizer,\n",
        "        X_test,\n",
        "        batch_size=batch_size\n",
        "    )\n",
        "\n",
        "    score_eval, X_eval_preds = get_model_score_and_predictions(\n",
        "        model, tokenizer, X_eval\n",
        "    )\n",
        "    \n",
        "    save_experiment(model,\n",
        "        X_train, X_train_preds,\n",
        "        X_test, X_test_preds,\n",
        "        X_eval, X_eval_preds,\n",
        "        folder_name=experiment_name)\n",
        "\n",
        "\n",
        "    X = pd.concat([\n",
        "        X_train.assign(\n",
        "            predicted_label=X_train_preds.values,\n",
        "            subset='train'\n",
        "        ),\n",
        "        X_test.assign(\n",
        "            predicted_label=X_test_preds.values,\n",
        "            subset='test'\n",
        "        ),\n",
        "        X_eval.assign(\n",
        "            predicted_label=X_eval_preds.values,\n",
        "            subset='eval'\n",
        "        )\n",
        "        ])\n",
        "\n",
        "    return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-22T10:50:49.923434Z",
          "iopub.status.busy": "2024-04-22T10:50:49.923171Z",
          "iopub.status.idle": "2024-04-22T10:50:49.934599Z",
          "shell.execute_reply": "2024-04-22T10:50:49.933667Z",
          "shell.execute_reply.started": "2024-04-22T10:50:49.923402Z"
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# X = experiment12()\n",
        "# display(result_matrix(X, [], metrics, use_subsets=True))\n",
        "# display(result_matrix(X, ['sourced_lang'], metrics, use_subsets=True))\n",
        "# display(result_matrix(X, ['sourced_lang', 'channel'],metrics , use_subsets=True))\n",
        "# # X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experiment 13. Train the model on the both uk and ru languages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experiment 14. Take a subset of the russian speaking and translated to uk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-22T10:50:49.936165Z",
          "iopub.status.busy": "2024-04-22T10:50:49.935881Z",
          "iopub.status.idle": "2024-04-22T10:50:49.947762Z",
          "shell.execute_reply": "2024-04-22T10:50:49.946929Z",
          "shell.execute_reply.started": "2024-04-22T10:50:49.936138Z"
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def experiment14():\n",
        "    '''\n",
        "    Train: cyrilic uk&ru\n",
        "    Test: cyrilic uk&ru\n",
        "    Eval: cyrilic uk&ru\n",
        "    '''\n",
        "    # Test configuration\n",
        "    X_train_n = 80000\n",
        "    X_test_n = 10000\n",
        "    X_eval_n = 10000\n",
        "    \n",
        "    sampling_random_state = 42\n",
        "    experiment_name = 'experiment-14'\n",
        "    model_name = \"google-bert/bert-base-multilingual-cased\"\n",
        "    tokenizer_name = \"google-bert/bert-base-multilingual-cased\"\n",
        "    batch_size = 8\n",
        "    epochs = 8\n",
        "\n",
        "    translator_batch_size = 8\n",
        "    translator = Translator()\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    \n",
        "    dataset = generate_dataset()\n",
        "    n = X_train_n + X_test_n + X_eval_n\n",
        "    n_uk = n//4\n",
        "    ru_0_sample = dataset[(dataset[DatasetFields.sourced_lang] == 'ru') & \\\n",
        "        (dataset[DatasetFields.label] == 1)].sample(n_uk, random_state=sampling_random_state)\n",
        "    dataset.loc[ru_0_sample.index] = translate_df(ru_0_sample, translator.translate, target_lang='uk',\n",
        "                                                  batch_size=translator_batch_size, \n",
        "                                                  device=device)\n",
        "    dataset.loc[ru_0_sample.index, 'sourced_lang'] = 'uk'\n",
        "    \n",
        "    X_train, X_test, X_eval = get_train_test_eval_from_dataset(\n",
        "        dataset,\n",
        "        X_train_n,\n",
        "        X_test_n,\n",
        "        X_eval_n,\n",
        "        random_state=sampling_random_state)\n",
        "    \n",
        "    X_train.to_csv('X_train_backup.csv')\n",
        "    X_test.to_csv('X_train_backup.csv')\n",
        "    X_eval.to_csv('X_train_backup.csv')\n",
        "\n",
        "    # Static configuration\n",
        "    # display(X_train.groupby(['label', 'sourced_lang']).agg('count'))\n",
        "    \n",
        "\n",
        "\n",
        "    # Preprocess dataset\n",
        "\n",
        "\n",
        "    # Train model\n",
        "    model, tokenizer = train_model_by_name(X_train,\n",
        "                                           model_name=model_name,\n",
        "                                           tokenizer_name=tokenizer_name,\n",
        "                                           batch_size=batch_size,\n",
        "                                           epochs=epochs)\n",
        "\n",
        "    # Score model\n",
        "    score_train, X_train_preds = get_model_score_and_predictions(\n",
        "        model,\n",
        "        tokenizer,\n",
        "        X_train,\n",
        "        batch_size=batch_size\n",
        "    )\n",
        "\n",
        "    \n",
        "    score_test, X_test_preds = get_model_score_and_predictions(\n",
        "        model,\n",
        "        tokenizer,\n",
        "        X_test,\n",
        "        batch_size=batch_size\n",
        "    )\n",
        "\n",
        "    score_eval, X_eval_preds = get_model_score_and_predictions(\n",
        "        model, tokenizer, X_eval\n",
        "    )\n",
        "    \n",
        "    save_experiment(model,\n",
        "        X_train, X_train_preds,\n",
        "        X_test, X_test_preds,\n",
        "        X_eval, X_eval_preds,\n",
        "        folder_name=experiment_name)\n",
        "\n",
        "    X = pd.concat([\n",
        "        X_train.assign(\n",
        "            predicted_label=X_train_preds.values,\n",
        "            subset='train'\n",
        "        ),\n",
        "        X_test.assign(\n",
        "            predicted_label=X_test_preds.values,\n",
        "            subset='test'\n",
        "        ),\n",
        "        X_eval.assign(\n",
        "            predicted_label=X_eval_preds.values,\n",
        "            subset='eval'\n",
        "        )\n",
        "        ])\n",
        "\n",
        "    return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-22T10:50:49.949161Z",
          "iopub.status.busy": "2024-04-22T10:50:49.948846Z",
          "iopub.status.idle": "2024-04-22T10:50:49.960074Z",
          "shell.execute_reply": "2024-04-22T10:50:49.959219Z",
          "shell.execute_reply.started": "2024-04-22T10:50:49.949133Z"
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from IPython.display import display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-22T10:50:49.961483Z",
          "iopub.status.busy": "2024-04-22T10:50:49.961175Z",
          "iopub.status.idle": "2024-04-22T10:50:49.969515Z",
          "shell.execute_reply": "2024-04-22T10:50:49.968661Z",
          "shell.execute_reply.started": "2024-04-22T10:50:49.961454Z"
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# X = experiment14()\n",
        "# display(result_matrix(X, [], metrics, use_subsets=True))\n",
        "# display(result_matrix(X, ['sourced_lang'], metrics, use_subsets=True))\n",
        "# display(result_matrix(X, ['sourced_lang', 'channel'],metrics , use_subsets=True))\n",
        "# # X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Enhancement ideas\n",
        "- Assume we want to write a multiple test in one notebook. It would be great if total statistics could be saved with row of name of the experiment and columns relevant metrics F1_train, F1_test, F1_ru_0\n",
        "- Output FN and FP counts for each language\n",
        "- Make experiment receive the sample size on which the experiment should be performed\n",
        "- Experiment can be a subclass. Parent class can save everything etc.\n",
        "- At this point it may be worth stop doing experiments and make this notebook clean so that everyone can take it and continue the work on the propaganda detection if necesary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Ouput dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "def write_dataset_to_file():\n",
        "    dataset = generate_dataset()\n",
        "    dataset.to_csv('dataset.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "# dataset = generate_dataset()\n",
        "# X_train, X_test, X_eval = get_train_test_eval_from_dataset(\n",
        "#     dataset,\n",
        "#     80_000,\n",
        "#     10_000,\n",
        "#     10_000,\n",
        "#     random_state=42)\n",
        "# X_train['subset'] = 'train'\n",
        "# X_test['subset'] = 'test'\n",
        "# X_eval['subset'] = 'eval'\n",
        "\n",
        "# pd.concat([\n",
        "#     X_train,\n",
        "#     X_test,\n",
        "#     X_eval\n",
        "# ]).to_csv('100k_sample_dataset.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [],
      "source": [
        "# #     80_000,\n",
        "# #     10_000,\n",
        "# #     10_000,\n",
        "# X_train_n = 80_000\n",
        "# X_test_n = 10_000\n",
        "# X_eval_n = 10_000\n",
        "# translator = Translator()\n",
        "# sampling_random_state=42\n",
        "# dataset = generate_dataset()\n",
        "# n = X_train_n + X_test_n + X_eval_n\n",
        "# n_uk = n//4\n",
        "# ru_0_sample = dataset[(dataset[DatasetFields.sourced_lang] == 'ru') & \\\n",
        "#     (dataset[DatasetFields.label] == 1)].sample(n_uk, random_state=sampling_random_state)\n",
        "# dataset.loc[ru_0_sample.index] = translate_df(ru_0_sample, translator.translate, target_lang='uk',\n",
        "#                                                 batch_size=8, \n",
        "#                                                 device='cuda')\n",
        "# dataset.loc[ru_0_sample.index, 'sourced_lang'] = 'uk'\n",
        "\n",
        "# X_train, X_test, X_eval = get_train_test_eval_from_dataset(\n",
        "#     dataset,\n",
        "#     X_train_n,\n",
        "#     X_test_n,\n",
        "#     X_eval_n,\n",
        "#     random_state=sampling_random_state)\n",
        "# pd.concat([\n",
        "#     X_train, X_test, X_eval\n",
        "# ]).to_csv('experiment3_100k_sampled_dataset.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "ename": "AssertionError",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[63], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m idf \u001b[38;5;241m=\u001b[39m get_language_inversed_dataset(subset\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m idf\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlanguage_inversed_dataset.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ],
      "source": [
        "idf = get_language_inversed_dataset(subset='test')\n",
        "idf.to_csv('language_inversed_dataset.csv')\n",
        "\n",
        "assert False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Researching what is huggingface returning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-22T10:50:49.970831Z",
          "iopub.status.busy": "2024-04-22T10:50:49.970542Z",
          "iopub.status.idle": "2024-04-22T10:50:49.978983Z",
          "shell.execute_reply": "2024-04-22T10:50:49.978195Z",
          "shell.execute_reply.started": "2024-04-22T10:50:49.970808Z"
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# model_name = 'google-bert/bert-base-multilingual-uncased'\n",
        "# tokenizer_name = 'google-bert/bert-base-multilingual-uncased'\n",
        "# model, tokenizer = get_model_tokenizer_pair(model_name, tokenizer_name)\n",
        "\n",
        "# are_layers_trainable = [param.requires_grad for param in model.bert.parameters()]\n",
        "# all(are_layers_trainable)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-22T10:50:49.980299Z",
          "iopub.status.busy": "2024-04-22T10:50:49.979981Z",
          "iopub.status.idle": "2024-04-22T10:50:49.989838Z",
          "shell.execute_reply": "2024-04-22T10:50:49.988962Z",
          "shell.execute_reply.started": "2024-04-22T10:50:49.980276Z"
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# # Number of telegram sources\n",
        "# dataset = generate_dataset()\n",
        "# test_dataset = get_language_inversed_dataset(subset='test')\n",
        "\n",
        "# df = pd.concat([dataset, test_dataset], axis='index')\n",
        "# df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-22T10:50:49.991148Z",
          "iopub.status.busy": "2024-04-22T10:50:49.990864Z",
          "iopub.status.idle": "2024-04-22T10:50:49.999465Z",
          "shell.execute_reply": "2024-04-22T10:50:49.998642Z",
          "shell.execute_reply.started": "2024-04-22T10:50:49.991125Z"
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# # how may channels did we parse in total\n",
        "# len(df['channel'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-22T10:50:50.001167Z",
          "iopub.status.busy": "2024-04-22T10:50:50.000337Z",
          "iopub.status.idle": "2024-04-22T10:50:50.012452Z",
          "shell.execute_reply": "2024-04-22T10:50:50.011618Z",
          "shell.execute_reply.started": "2024-04-22T10:50:50.001143Z"
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# # how many channels by label and language\n",
        "# sns.catplot(x='label', kind='count', data=df, hue='sourced_lang')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-22T10:50:50.013672Z",
          "iopub.status.busy": "2024-04-22T10:50:50.013418Z",
          "iopub.status.idle": "2024-04-22T10:50:50.022027Z",
          "shell.execute_reply": "2024-04-22T10:50:50.021129Z",
          "shell.execute_reply.started": "2024-04-22T10:50:50.013640Z"
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# df.pivot_table('channel',index='label', columns='sourced_lang', aggfunc='count')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Results and storyline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-22T10:50:50.023371Z",
          "iopub.status.busy": "2024-04-22T10:50:50.023112Z",
          "iopub.status.idle": "2024-04-22T10:51:11.097203Z",
          "shell.execute_reply": "2024-04-22T10:51:11.096001Z",
          "shell.execute_reply.started": "2024-04-22T10:50:50.023349Z"
        },
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1DLqIg-g9gfdr-1L7lM2eiQ7-0WLJZhU_\n",
            "To: /workspace/dataset_story.csv\n",
            "100%|██████████████████████████████████████| 49.5M/49.5M [00:00<00:00, 60.1MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1rq50OQj5WN2-1ubOx0HpnXqulx_SF4OT\n",
            "To: /workspace/propagandistic_story.csv\n",
            "100%|██████████████████████████████████████| 10.9M/10.9M [00:00<00:00, 33.7MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown 1DLqIg-g9gfdr-1L7lM2eiQ7-0WLJZhU_ -O dataset_story.csv\n",
        "!gdown 1rq50OQj5WN2-1ubOx0HpnXqulx_SF4OT -O propagandistic_story.csv\n",
        "# !gdown 1Ic0j2lqq8k9Y6OFRtNNSJ1vA9ibukrp- -O 'model.pkl'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-22T10:51:11.102453Z",
          "iopub.status.busy": "2024-04-22T10:51:11.102066Z",
          "iopub.status.idle": "2024-04-22T10:51:12.746915Z",
          "shell.execute_reply": "2024-04-22T10:51:12.745868Z",
          "shell.execute_reply.started": "2024-04-22T10:51:11.102416Z"
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "story_df = (\n",
        "    pd.concat([\n",
        "        pd.read_csv('dataset_story.csv', index_col=0),\n",
        "        pd.read_csv('propagandistic_story.csv', index_col=0)\n",
        "    ])\n",
        "    .pipe(rename_columns, column_mapping=parser_column_mapping)\n",
        "    .pipe(handle_missing_values)\n",
        "    .pipe(cast_types, column_type_mapping=parser_column_type_mapping)\n",
        "    .pipe(channel_url_to_name)\n",
        "           )\n",
        "\n",
        "presumed_labels_mapping = {\n",
        "    1: [\n",
        "        'HolodniyYar',\n",
        "        'yurasumy'\n",
        "        \n",
        "    ],\n",
        "    0: [\n",
        "        'ToBeOr_Official',\n",
        "        'lachentyt',\n",
        "        'truexanewsua'\n",
        "    ]\n",
        "}\n",
        "presumed_languages = {\n",
        "    'uk': ['truexanewsua', 'lachentyt'],\n",
        "    'ru': ['ToBeOr_Official', 'HolodniyYar', 'yurasumy' ]\n",
        "}\n",
        "\n",
        "\n",
        "for lang, channel_list in presumed_languages.items():\n",
        "    story_df.loc[story_df['channel'].isin(channel_list),\n",
        "             DatasetFields.sourced_lang] = lang\n",
        "    \n",
        "for label, channel_list in presumed_labels_mapping.items():\n",
        "    story_df.loc[story_df['channel'].isin(channel_list),\n",
        "         DatasetFields.label] = label\n",
        "story_df[DatasetFields.label] = story_df[DatasetFields.label].astype(int)\n",
        "story_df = story_df.set_index('date').sort_index()\n",
        "story_df.to_csv('story_dataset.csv', index=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Untitled.ipynb\t\t       model.pkl\n",
            "Untitled1.ipynb\t\t       output.log\n",
            "X_train_backup.csv\t       propaganda_ru.csv\n",
            "checkpoints\t\t       propagandistic_story.csv\n",
            "dataset\t\t\t       story_dataset.csv\n",
            "dataset_story.csv\t       test_tcon.ipybn--log-output\n",
            "diploma-thesis-notebook.ipynb  test_tcon.ipynb\n",
            "experiment-14\t\t       test_tqdm.ipynb\n",
            "experiment3\t\t       test_tqdm.nbconvert.ipynb\n",
            "factual_uk.csv\t\t       translation-pipeline\n",
            "language_agnostic.csv\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-22T10:58:52.150944Z",
          "iopub.status.busy": "2024-04-22T10:58:52.150255Z",
          "iopub.status.idle": "2024-04-22T10:59:06.752585Z",
          "shell.execute_reply": "2024-04-22T10:59:06.750761Z",
          "shell.execute_reply.started": "2024-04-22T10:58:52.150911Z"
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "device = 'cuda'\n",
        "model = torch.load('model.pkl', map_location=device)\n",
        "tokenizer_name = \"bert-base-multilingual-cased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
        "batch_size = 8\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test 1. Without translation, first days of the war"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-22T10:51:35.875535Z",
          "iopub.status.idle": "2024-04-22T10:51:35.875981Z",
          "shell.execute_reply": "2024-04-22T10:51:35.875807Z",
          "shell.execute_reply.started": "2024-04-22T10:51:35.875788Z"
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# inference_df = story_df.loc['2022-02-24':'2022-05-01'].reset_index('date')\n",
        "# inference_df['date-only'] = inference_df['date'].dt.date\n",
        "# plot_messages_by_date(inference_df)\n",
        "# sampled_inf_df = inference_df.groupby('channel').apply(\n",
        "#     partial(uniform_date_sample, sample_size=200)).reset_index(drop=True)\n",
        "# plot_messages_by_date(sampled_inf_df)\n",
        "\n",
        "# score_test, X_test_preds = get_model_score_and_predictions(\n",
        "#     model,\n",
        "#     tokenizer,\n",
        "#     sampled_inf_df,\n",
        "#     batch_size=batch_size\n",
        "# )\n",
        "# results_df = sampled_inf_df.assign(\n",
        "#     predicted_label=X_test_preds\n",
        "# )\n",
        "\n",
        "# plot_messages_by_date(results_df, hue='predicted_label', col_order=['HolodniyYar', 'truexanewsua', 'ToBeOr_Official', 'lachentyt' ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-22T10:51:35.877642Z",
          "iopub.status.idle": "2024-04-22T10:51:35.877975Z",
          "shell.execute_reply": "2024-04-22T10:51:35.877829Z",
          "shell.execute_reply.started": "2024-04-22T10:51:35.877815Z"
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def explore_model_choices(df):\n",
        "    return (df.groupby('channel')\n",
        "     .apply(partial(sample_tp_fn, sample_size=2))[['text', 'label', 'predicted_label', 'original_text']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test 2. With translation. First months of the war"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-22T10:51:35.879413Z",
          "iopub.status.idle": "2024-04-22T10:51:35.879737Z",
          "shell.execute_reply": "2024-04-22T10:51:35.879580Z",
          "shell.execute_reply.started": "2024-04-22T10:51:35.879567Z"
        },
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "630b36bedba14b67ab2ec6376101909f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.42236025 0.61087866]\n",
            "INFO:matplotlib.category:Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\n",
            "INFO:matplotlib.category:Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>recall</th>\n",
              "      <th>precision</th>\n",
              "      <th>f1</th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>channel</th>\n",
              "      <th>label</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>HolodniyYar</th>\n",
              "      <th>1</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>200.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ToBeOr_Official</th>\n",
              "      <th>0</th>\n",
              "      <td>0.14</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.245614</td>\n",
              "      <td>200.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lachentyt</th>\n",
              "      <th>0</th>\n",
              "      <td>0.42</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.591549</td>\n",
              "      <td>200.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>truexanewsua</th>\n",
              "      <th>0</th>\n",
              "      <td>0.29</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.449612</td>\n",
              "      <td>200.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>yurasumy</th>\n",
              "      <th>1</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>200.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       recall  precision        f1  count\n",
              "channel         label                                    \n",
              "HolodniyYar     1        0.00        0.0  0.000000  200.0\n",
              "ToBeOr_Official 0        0.14        1.0  0.245614  200.0\n",
              "lachentyt       0        0.42        1.0  0.591549  200.0\n",
              "truexanewsua    0        0.29        1.0  0.449612  200.0\n",
              "yurasumy        1        0.00        0.0  0.000000  200.0"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>predicted_label</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>channel</th>\n",
              "      <th>true_prediction</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"4\" valign=\"top\">HolodniyYar</th>\n",
              "      <th rowspan=\"2\" valign=\"top\">False</th>\n",
              "      <th>170</th>\n",
              "      <td>Результаты обстрела российской армией города Харькова\\n\\nМы долго думали, ставить это или нет. Но решили все-таки поставить. Во дворах лежат трупы мирных жителей. Труха пишет, люди вышли за водой.\\n\\nКошмар.\\n\\nИнсайдер UA  | Подписаться</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>Уважаемые пропагандисты! Вы если пытаетесь распространить фейки, то делайте это грамотно! \\n\\nСначала выложили видео под название \"Разбитая российская колонна в Харькове\", на котором нет даже ни одной капли крови оккупантов, ни одного трупа. Где же они?\\n\\nНо нет же. Арестович позже выкладывает это видео с подписью \"Брошенная техника\", что уже больше похоже на правду. Определитесь уже с концепцией!\\n\\nПлохо!</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">True</th>\n",
              "      <th>110</th>\n",
              "      <td>‼️🇺🇦 ВАЖНАЯ ИНФОРМАЦИЯ‼️\\n\\nМне в обратную связь постоянно пишут - \"как можно обменять пленных и забрать тела?\"\\n\\nПишу этот пояснительный пост. \\n\\n📌Во-первых, пленных сейчас никто не отдаст. Причина - потому-что их снова заставят идти на войну (это со слов представителя противника). Вопрос с получением свежих фото или видео от противника прорабатывается!\\n\\n📌Во-вторых, для того, чтобы тела наших ребят доставить домой нужно организовать ряд мероприятий. Руководство страны, в частности министерства обороны и ВСУ, должно сотрудничать с Международным Комитетом Красного Креста. Как я уже писал, противник готов отдавать тела, но по причине того, что наша сторона не забирает их, противник собирает ДНК убитых и хоронит в братских могилах. \\n\\nЯ не знаю, кого уже похоронили, а кого нет! И не знаю, почему руководство не забирает тела! Есть несколько версий, но оглашать их пока не хочу. \\n\\nВ чем я уверен, так это в том, что нужно теребить власть, чтобы она начала действовать. Иначе мы так и не увидим наших родных, а будем опозновать их по ДНК.\\n\\nНУЖНО БРАТЬ СУДЬБУ НАШИХ ХЛОПЦЕВ В СВОИ РУКИ.\\n\\n@HolodniyYar</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>Ракетный залп в Херсонской области. \\n\\nПодписаться</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"4\" valign=\"top\">ToBeOr_Official</th>\n",
              "      <th rowspan=\"2\" valign=\"top\">False</th>\n",
              "      <th>245</th>\n",
              "      <td>​❗️Германия договорилась о поставках газа из Катара. Глава Минфина ФРГ согласовал в Дохе \"долгосрочное энергетическое партнерство\", включающее поставки СПГ.\\n\\nГермания активизирует усилия с целью стать менее зависимой от российского газа. Катар - один из крупнейших экспортеров сжиженного газа и третий по запасам природного газа в мире.\\n\\nПосле встречи в Дохе с эмиром Катара шейхом Тамимом бен Хамадом Аль Тани министр экономики ФРГ Роберт Хабек заявил, что \"эмир продемонстрировал даже более широкую поддержку, чем ожидалось\".</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>212</th>\n",
              "      <td>Фильм про «Дождь», который сняли с большого проката за день до закрытия канала, выложили на ютуб.</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">True</th>\n",
              "      <th>295</th>\n",
              "      <td>❗️200 тысяч человек рискуют потерять работу из-за ухода иностранных компаний из РФ, - Собянин.\\n\\nЧто такое 200 тысяч человек? Это приблизительно 4 Изюма, который с таким трудом и потерями спустя больше месяца боёв взяла под контроль армия РФ (и не факт, что не потеряет его, в этом направлении идут ожесточённые бои).</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>377</th>\n",
              "      <td>Христо Грозев и Gulagu.net, ссылаясь на свои источники, сообщили, что в России задержан замначальника Росгвардии Роман Гаврилов.\\n\\nПо словам Gulagu.net, Гаврилов является одним из самых близких к Виктору Золотову офицеров спецслужб. Они оба ранее служили в ФСО и занимались личной охраной Путина и Медведева.\\n\\nГаврилова подозревают в шпионаже и утечке данных о перемещении российских войск в Украине, гибели более 100 росгвардейцев, а также срыве ряда мероприятий по захвату территорий и стратегических объектов Украины.\\n\\nСообщается также, что Золотов не может попасть на приём к Путину.\\n\\nВ то же время, депутат Хинштейн (если не знаете, кто это - вот мы писали) опроверг информацию о задержании и сказал, что он недавно сам говорил с Гавриловым.\\n\\nНа фото: Гаврилов (в центре) и Хинштейн (справа).</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"4\" valign=\"top\">lachentyt</th>\n",
              "      <th rowspan=\"2\" valign=\"top\">False</th>\n",
              "      <th>513</th>\n",
              "      <td>Знищення орків 22 бригади ГРУ росії полком «Азов»</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>577</th>\n",
              "      <td>⚡️British Petroleum прекратит заключение новых сделок на покупку нефти и газа из России — Bloomberg</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">True</th>\n",
              "      <th>534</th>\n",
              "      <td>Наші військові тримають небо над Україною. Знищено черговий ворожий СУ-25 разом з пілотом.\\nВсього за час відкритої війни збито 37 літаків і 37 гелікоптерів противника.</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>481</th>\n",
              "      <td>«Во время нашей сегодняшней беседы министр энергетики Леонор Гевесслер и я согласились, что зависимость от импорта природного газа из России должна быть быстро снижена и что расширение использования возобновляемых источников энергии и мер по повышению эффективности должно быть значительно ускорено.\\n\\nФедеральное правительство работает над планом отказа от российского природного газа. Я приветствую это, потому что время имеет существенное значение. Не только из-за агрессивной войны россии против Украины, но и из соображений защиты климата.» - сообщил в Twitter федеральный президент Австрии Александр Ван дер Беллен.\\n\\nЭто Австрия, которая недавно заявляла о газовой зависимости с рФ на 80% и говорила, что на это \"может уйти несколько лет\"</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"4\" valign=\"top\">truexanewsua</th>\n",
              "      <th rowspan=\"2\" valign=\"top\">False</th>\n",
              "      <th>791</th>\n",
              "      <td>#ИтогиТрухи Главное этим утром:\\n\\n– Оккупанты нанесли несколько ракетных ударов по Одессе. По словам мэра Геннадия Труханова, били по объектам критической инфраструктуры. Пострадавших нет.\\n\\n– На Луганщине 4 мэра городов оказались предателями. Об этом сообщил глава Луганской ОВА Сергей Гайдай.\\n\\n– Ирина Верещук заявила, что в российском плену находится 11 украинских мэров.\\n\\nТРУХА⚡️Украина | Прислать новость</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>679</th>\n",
              "      <td>#нампишут \\n\\nХарьков. Военному госпиталю срочно нужна помощь - трактор с ковшом для рытья  траншеи. Контактное лицо 0507169828 Константин</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">True</th>\n",
              "      <th>642</th>\n",
              "      <td>Знищена ворожа колона біля Миколаїва.\\n\\n#stoprussia</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>743</th>\n",
              "      <td>Що робити якщо в ваш населений пункт прийшов ворог.\\n\\nЯк поводитись під час бойових дій. \\n\\nЯк вберегтись від різного виду обстрілів.</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"4\" valign=\"top\">yurasumy</th>\n",
              "      <th rowspan=\"2\" valign=\"top\">False</th>\n",
              "      <th>975</th>\n",
              "      <td>Правда, вот пока ценник мне не нравится. Его можно и нужно уменьшить хотя бы процентов на 30%</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>896</th>\n",
              "      <td>Война на Украине (13.03.22 на 20:00): Ситуация на фронтах. Возможна ли капитуляция ВСУ?\\n\\nПодводим итоги боев 13 марта 2022 года на фронтах Украины. А еще поговорим сегодня о потерях сторон и о … возможной капитуляции ВСУ\\n\\nhttps://www.youtube.com/watch?v=saIQzNBxtsg</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">True</th>\n",
              "      <th>911</th>\n",
              "      <td>И возвращаясь к предыдущему посту, как тут не вспомнить лучшую роль \"эксперта\" Люси Арестович, которая/ый (нужное подчеркнуть), несколько лет назад, по-сути говорил/ла о себе правду. \"Девочка-загадка\", морочащая людям голову )))\\nП.С. Сборище клоунов коакое-то. Разве может страна с такими правителями и экспертами, что-то выиграть и не развалиться? Вопрос риторический.</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>902</th>\n",
              "      <td>Пишут из Энергодара (Запорожская область, там, где пресловутая АЭС):\\n\"1. Военный комендант есть .Ну вроде как. По крайней мере указано куда обращаться.\\n2 .Создан народный совет по самоорганизации города. Казачки+афганцы.\\n3. Наши(*) привезли бензин 95й.И даже настроили заправку,одну на город,но уже радует.Наличка,по 60грн за литр.\\n4. Решается вопрос о поставках дизеля,надо начинать посевную.\\n5. Мэр города истерит в Телеге,на тему народного совета,что мол самозванцы и не под юрисдикцией Украины.Из этого делаю вывод,что дело помалу сдвигается с мертвой точки.\"\\n\\n(*) Наши для автора текста - россияне. Автор - местная жительница.</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             text  \\\n",
              "channel         true_prediction                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
              "HolodniyYar     False           170  Результаты обстрела российской армией города Харькова\\n\\nМы долго думали, ставить это или нет. Но решили все-таки поставить. Во дворах лежат трупы мирных жителей. Труха пишет, люди вышли за водой.\\n\\nКошмар.\\n\\nИнсайдер UA  | Подписаться                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
              "                                148  Уважаемые пропагандисты! Вы если пытаетесь распространить фейки, то делайте это грамотно! \\n\\nСначала выложили видео под название \"Разбитая российская колонна в Харькове\", на котором нет даже ни одной капли крови оккупантов, ни одного трупа. Где же они?\\n\\nНо нет же. Арестович позже выкладывает это видео с подписью \"Брошенная техника\", что уже больше похоже на правду. Определитесь уже с концепцией!\\n\\nПлохо!                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
              "                True            110  ‼️🇺🇦 ВАЖНАЯ ИНФОРМАЦИЯ‼️\\n\\nМне в обратную связь постоянно пишут - \"как можно обменять пленных и забрать тела?\"\\n\\nПишу этот пояснительный пост. \\n\\n📌Во-первых, пленных сейчас никто не отдаст. Причина - потому-что их снова заставят идти на войну (это со слов представителя противника). Вопрос с получением свежих фото или видео от противника прорабатывается!\\n\\n📌Во-вторых, для того, чтобы тела наших ребят доставить домой нужно организовать ряд мероприятий. Руководство страны, в частности министерства обороны и ВСУ, должно сотрудничать с Международным Комитетом Красного Креста. Как я уже писал, противник готов отдавать тела, но по причине того, что наша сторона не забирает их, противник собирает ДНК убитых и хоронит в братских могилах. \\n\\nЯ не знаю, кого уже похоронили, а кого нет! И не знаю, почему руководство не забирает тела! Есть несколько версий, но оглашать их пока не хочу. \\n\\nВ чем я уверен, так это в том, что нужно теребить власть, чтобы она начала действовать. Иначе мы так и не увидим наших родных, а будем опозновать их по ДНК.\\n\\nНУЖНО БРАТЬ СУДЬБУ НАШИХ ХЛОПЦЕВ В СВОИ РУКИ.\\n\\n@HolodniyYar   \n",
              "                                99   Ракетный залп в Херсонской области. \\n\\nПодписаться                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
              "ToBeOr_Official False           245  ​❗️Германия договорилась о поставках газа из Катара. Глава Минфина ФРГ согласовал в Дохе \"долгосрочное энергетическое партнерство\", включающее поставки СПГ.\\n\\nГермания активизирует усилия с целью стать менее зависимой от российского газа. Катар - один из крупнейших экспортеров сжиженного газа и третий по запасам природного газа в мире.\\n\\nПосле встречи в Дохе с эмиром Катара шейхом Тамимом бен Хамадом Аль Тани министр экономики ФРГ Роберт Хабек заявил, что \"эмир продемонстрировал даже более широкую поддержку, чем ожидалось\".                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
              "                                212  Фильм про «Дождь», который сняли с большого проката за день до закрытия канала, выложили на ютуб.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
              "                True            295  ❗️200 тысяч человек рискуют потерять работу из-за ухода иностранных компаний из РФ, - Собянин.\\n\\nЧто такое 200 тысяч человек? Это приблизительно 4 Изюма, который с таким трудом и потерями спустя больше месяца боёв взяла под контроль армия РФ (и не факт, что не потеряет его, в этом направлении идут ожесточённые бои).                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
              "                                377  Христо Грозев и Gulagu.net, ссылаясь на свои источники, сообщили, что в России задержан замначальника Росгвардии Роман Гаврилов.\\n\\nПо словам Gulagu.net, Гаврилов является одним из самых близких к Виктору Золотову офицеров спецслужб. Они оба ранее служили в ФСО и занимались личной охраной Путина и Медведева.\\n\\nГаврилова подозревают в шпионаже и утечке данных о перемещении российских войск в Украине, гибели более 100 росгвардейцев, а также срыве ряда мероприятий по захвату территорий и стратегических объектов Украины.\\n\\nСообщается также, что Золотов не может попасть на приём к Путину.\\n\\nВ то же время, депутат Хинштейн (если не знаете, кто это - вот мы писали) опроверг информацию о задержании и сказал, что он недавно сам говорил с Гавриловым.\\n\\nНа фото: Гаврилов (в центре) и Хинштейн (справа).                                                                                                                                                                                                                                                                                                                         \n",
              "lachentyt       False           513  Знищення орків 22 бригади ГРУ росії полком «Азов»                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
              "                                577  ⚡️British Petroleum прекратит заключение новых сделок на покупку нефти и газа из России — Bloomberg                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
              "                True            534  Наші військові тримають небо над Україною. Знищено черговий ворожий СУ-25 разом з пілотом.\\nВсього за час відкритої війни збито 37 літаків і 37 гелікоптерів противника.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
              "                                481  «Во время нашей сегодняшней беседы министр энергетики Леонор Гевесслер и я согласились, что зависимость от импорта природного газа из России должна быть быстро снижена и что расширение использования возобновляемых источников энергии и мер по повышению эффективности должно быть значительно ускорено.\\n\\nФедеральное правительство работает над планом отказа от российского природного газа. Я приветствую это, потому что время имеет существенное значение. Не только из-за агрессивной войны россии против Украины, но и из соображений защиты климата.» - сообщил в Twitter федеральный президент Австрии Александр Ван дер Беллен.\\n\\nЭто Австрия, которая недавно заявляла о газовой зависимости с рФ на 80% и говорила, что на это \"может уйти несколько лет\"                                                                                                                                                                                                                                                                                                                                                                                    \n",
              "truexanewsua    False           791  #ИтогиТрухи Главное этим утром:\\n\\n– Оккупанты нанесли несколько ракетных ударов по Одессе. По словам мэра Геннадия Труханова, били по объектам критической инфраструктуры. Пострадавших нет.\\n\\n– На Луганщине 4 мэра городов оказались предателями. Об этом сообщил глава Луганской ОВА Сергей Гайдай.\\n\\n– Ирина Верещук заявила, что в российском плену находится 11 украинских мэров.\\n\\nТРУХА⚡️Украина | Прислать новость                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
              "                                679  #нампишут \\n\\nХарьков. Военному госпиталю срочно нужна помощь - трактор с ковшом для рытья  траншеи. Контактное лицо 0507169828 Константин                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
              "                True            642  Знищена ворожа колона біля Миколаїва.\\n\\n#stoprussia                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
              "                                743  Що робити якщо в ваш населений пункт прийшов ворог.\\n\\nЯк поводитись під час бойових дій. \\n\\nЯк вберегтись від різного виду обстрілів.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
              "yurasumy        False           975  Правда, вот пока ценник мне не нравится. Его можно и нужно уменьшить хотя бы процентов на 30%                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
              "                                896  Война на Украине (13.03.22 на 20:00): Ситуация на фронтах. Возможна ли капитуляция ВСУ?\\n\\nПодводим итоги боев 13 марта 2022 года на фронтах Украины. А еще поговорим сегодня о потерях сторон и о … возможной капитуляции ВСУ\\n\\nhttps://www.youtube.com/watch?v=saIQzNBxtsg                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
              "                True            911  И возвращаясь к предыдущему посту, как тут не вспомнить лучшую роль \"эксперта\" Люси Арестович, которая/ый (нужное подчеркнуть), несколько лет назад, по-сути говорил/ла о себе правду. \"Девочка-загадка\", морочащая людям голову )))\\nП.С. Сборище клоунов коакое-то. Разве может страна с такими правителями и экспертами, что-то выиграть и не развалиться? Вопрос риторический.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
              "                                902  Пишут из Энергодара (Запорожская область, там, где пресловутая АЭС):\\n\"1. Военный комендант есть .Ну вроде как. По крайней мере указано куда обращаться.\\n2 .Создан народный совет по самоорганизации города. Казачки+афганцы.\\n3. Наши(*) привезли бензин 95й.И даже настроили заправку,одну на город,но уже радует.Наличка,по 60грн за литр.\\n4. Решается вопрос о поставках дизеля,надо начинать посевную.\\n5. Мэр города истерит в Телеге,на тему народного совета,что мол самозванцы и не под юрисдикцией Украины.Из этого делаю вывод,что дело помалу сдвигается с мертвой точки.\"\\n\\n(*) Наши для автора текста - россияне. Автор - местная жительница.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
              "\n",
              "                                     label  predicted_label  \n",
              "channel         true_prediction                              \n",
              "HolodniyYar     False           170  1      0                \n",
              "                                148  1      0                \n",
              "                True            110  1      1                \n",
              "                                99   1      1                \n",
              "ToBeOr_Official False           245  0      1                \n",
              "                                212  0      1                \n",
              "                True            295  0      0                \n",
              "                                377  0      0                \n",
              "lachentyt       False           513  0      1                \n",
              "                                577  0      1                \n",
              "                True            534  0      0                \n",
              "                                481  0      0                \n",
              "truexanewsua    False           791  0      1                \n",
              "                                679  0      1                \n",
              "                True            642  0      0                \n",
              "                                743  0      0                \n",
              "yurasumy        False           975  1      0                \n",
              "                                896  1      0                \n",
              "                True            911  1      1                \n",
              "                                902  1      1                "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1117.99x1000 with 4 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "translator = Translator()\n",
        "\n",
        "start_date = '2022-02-24'\n",
        "end_date = '2022-05-01'\n",
        "\n",
        "first_months_df = calculate_time_dynamics(story_df,\n",
        "                                     start_date=start_date,\n",
        "                                     end_date=end_date,\n",
        "                                     model=model,\n",
        "                                     tokenizer=tokenizer,\n",
        "                                     batch_size=batch_size,\n",
        "                                     device=device)\n",
        "\n",
        "plot_messages_by_date(first_months_df, hue='predicted_label', col_order=['HolodniyYar', 'truexanewsua', 'ToBeOr_Official', 'lachentyt' ])\n",
        "display(result_matrix(first_months_df, ['channel'],metrics ))\n",
        "display(first_months_df.groupby('channel').apply(partial(sample_tp_fn, sample_size=2))[['text', 'label', 'predicted_label']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-22T10:51:35.880662Z",
          "iopub.status.idle": "2024-04-22T10:51:35.881031Z",
          "shell.execute_reply": "2024-04-22T10:51:35.880845Z",
          "shell.execute_reply.started": "2024-04-22T10:51:35.880831Z"
        },
        "trusted": true
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "display(first_months_df.groupby('channel').apply(partial(sample_tp_fn, sample_size=1))[['text', 'label', 'predicted_label','original_text']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-22T10:51:35.882619Z",
          "iopub.status.idle": "2024-04-22T10:51:35.883102Z",
          "shell.execute_reply": "2024-04-22T10:51:35.882859Z",
          "shell.execute_reply.started": "2024-04-22T10:51:35.882840Z"
        },
        "trusted": true
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "output_df = (result_matrix(first_months_df, ['channel'],metrics )\n",
        " .reset_index()\n",
        " .set_index(['label'])\n",
        " .sort_index()[['channel', 'recall']]\n",
        " .rename(columns={'channel' : 'Channel', 'recall' : 'Recall Score'})\n",
        " )\n",
        "output_df.index.name = 'Label'\n",
        "print(output_df.to_latex())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-22T10:51:35.884207Z",
          "iopub.status.idle": "2024-04-22T10:51:35.884634Z",
          "shell.execute_reply": "2024-04-22T10:51:35.884429Z",
          "shell.execute_reply.started": "2024-04-22T10:51:35.884410Z"
        },
        "trusted": true
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "first_months_df.set_index('date').sort_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-22T10:51:35.885822Z",
          "iopub.status.idle": "2024-04-22T10:51:35.886269Z",
          "shell.execute_reply": "2024-04-22T10:51:35.886063Z",
          "shell.execute_reply.started": "2024-04-22T10:51:35.886044Z"
        },
        "trusted": true
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "'''\n",
        "Right now to illustrate how model performs I just output the count of the messages each day\n",
        "What I want to communicate is how many messages were written in the channel on that day\n",
        "and what percentage what classified and how\n",
        "\n",
        "I image a plot that has days or a couple of days combined on the x\n",
        "and bars stacked on top of each other\n",
        "\n",
        "Cons: communicates percentage and the count\n",
        "\n",
        "I want a count plot of messages and one bar has two colors depending \n",
        "on the percentage of the particular class\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-22T10:51:35.887393Z",
          "iopub.status.idle": "2024-04-22T10:51:35.887836Z",
          "shell.execute_reply": "2024-04-22T10:51:35.887618Z",
          "shell.execute_reply.started": "2024-04-22T10:51:35.887599Z"
        },
        "trusted": true
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# plt.figure(dpi=1200)\n",
        "fig, ax = plt.subplots()\n",
        "message_counts = (first_months_df\n",
        "                  .set_index('date')\n",
        "                  .groupby(['predicted_label']).\n",
        "                  resample('7d')\n",
        "                  .count()['text'])\n",
        "\n",
        "total_daily = message_counts.reset_index().groupby('date')['text'].sum()\n",
        "\n",
        "secion_indices = [0, 1]\n",
        "bottom = np.zeros(len(message_counts) // 2)\n",
        "width = 5\n",
        "for i in secion_indices:\n",
        "    bars = ax.bar(message_counts.loc[i].index, message_counts.loc[i].values, \n",
        "        width=width,\n",
        "           label=i,\n",
        "          bottom=bottom)\n",
        "    \n",
        "    \n",
        "    percentage = message_counts.loc[i] / total_daily * 100\n",
        "    for bar_i, bar in enumerate(bars):\n",
        "        text = f'{percentage.iloc[bar_i].astype(int)}%'\n",
        "        yval = bar.get_height()\n",
        "        ax.text(bar.get_x() + bar.get_width()/2,  bottom[bar_i]+ yval / 2, text, \n",
        "        va='center', ha='center', color='white')\n",
        "        \n",
        "    bottom += message_counts.loc[i].values\n",
        "    \n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "handles, labels = plt.gca().get_legend_handles_labels()\n",
        "order = [1, 0]\n",
        "plt.legend([handles[idx] for idx in order],[labels[idx] for idx in order])\n",
        "\n",
        "\n",
        "# plt.grid()\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Number of messages')\n",
        "plt.title('Amount of messages predicted by the model');\n",
        "\n",
        "# We need to have array of bottom rows that is messages \n",
        "# we need to have array of above rows\n",
        "\n",
        "# output the score by day (nice idea!!!, well done)\n",
        "plt.savefig('test.pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-22T10:51:35.889312Z",
          "iopub.status.idle": "2024-04-22T10:51:35.889761Z",
          "shell.execute_reply": "2024-04-22T10:51:35.889545Z",
          "shell.execute_reply.started": "2024-04-22T10:51:35.889526Z"
        },
        "trusted": true
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# Plot with precision scores for each channel\n",
        "# I want to have a function that will draw a bar plot at specified axis\n",
        "# The function should accept a set of labels, a set of values and a set of text \n",
        "# for each value\n",
        "\n",
        "# plt.figure(dpi=1200)\n",
        "\n",
        "def stacked_bar_plot(xtick_labels, values, bar_texts, legend_labels, inversed_legend_order=True, ax=None,\n",
        "                    colors=None):\n",
        "\n",
        "    if ax is None:\n",
        "        _, ax = plt.subplots()\n",
        "        \n",
        "\n",
        "\n",
        "    m, n = values.shape\n",
        "    bottom = np.zeros(n)\n",
        "    width = 5\n",
        "    \n",
        "    bar_kwargs = [{} for _ in range(n)]\n",
        "    if colors is not None:\n",
        "        for i in range(m):\n",
        "            bar_kwargs[i]['color'] = colors[i]\n",
        "\n",
        "    for i in range(m):\n",
        "        bar_values = values[i]\n",
        "        bars = ax.bar(xtick_labels, bar_values, \n",
        "            width=width,\n",
        "            label=legend_labels[i],\n",
        "            bottom=bottom,\n",
        "                     **bar_kwargs[i])\n",
        "\n",
        "        for j in range(len(bars)):\n",
        "            bar = bars[j]\n",
        "            text = bar_texts[i, j]\n",
        "            yval = bar.get_height()\n",
        "            ax.text(bar.get_x() + bar.get_width()/2,  bottom[j]+ yval / 2, text, \n",
        "            va='center', ha='center', color='white')\n",
        "\n",
        "        bottom += bar_values\n",
        "\n",
        "        \n",
        "    plt.xticks(xtick_labels, rotation=45)\n",
        "\n",
        "    if inversed_legend_order:\n",
        "        handles, labels = plt.gca().get_legend_handles_labels()\n",
        "        order = [1, 0]\n",
        "        plt.legend([handles[idx] for idx in order],[labels[idx] for idx in order])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-22T10:51:35.891634Z",
          "iopub.status.idle": "2024-04-22T10:51:35.892092Z",
          "shell.execute_reply": "2024-04-22T10:51:35.891863Z",
          "shell.execute_reply.started": "2024-04-22T10:51:35.891845Z"
        },
        "trusted": true
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "ncol = 2\n",
        "nrow = 3\n",
        "\n",
        "plt.figure(figsize=(16, 10))\n",
        "\n",
        "for idx, channel in enumerate(first_months_df.channel.unique()):\n",
        "    channel_df = first_months_df[first_months_df['channel'] == channel]\n",
        "    ax = plt.subplot(nrow, ncol, idx + 1)\n",
        "    \n",
        "    message_counts = (channel_df\n",
        "                      .set_index('date')\n",
        "                      .groupby(['predicted_label']).\n",
        "                      resample('7d')\n",
        "                      .count()['text'])\n",
        "\n",
        "    total_daily = message_counts.reset_index().groupby('date')['text'].sum()\n",
        "    xtick_labels = message_counts.loc[0].index\n",
        "    display(message_counts)\n",
        "    values = np.array([\n",
        "        message_counts.loc[0].values,\n",
        "        message_counts.loc[1].values\n",
        "    ])\n",
        "    bar_precents = np.array([\n",
        "         message_counts.loc[0] / total_daily * 100,\n",
        "        message_counts.loc[1] / total_daily * 100\n",
        "    ])\n",
        "    bar_texts = np.vectorize(lambda x: f\"{x:.0f}%\")(bar_precents)\n",
        "    legend_labels = [\n",
        "        'Non-propaganda',\n",
        "        'Propaganda'\n",
        "    ]\n",
        "    # draw this for each \n",
        "    stacked_bar_plot(\n",
        "        xtick_labels,\n",
        "        values,\n",
        "        bar_texts,\n",
        "        legend_labels,\n",
        "        ax=ax\n",
        "    )\n",
        "    ax.set_title(f'Channel {channel}')\n",
        "    \n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-22T10:51:35.893267Z",
          "iopub.status.idle": "2024-04-22T10:51:35.893706Z",
          "shell.execute_reply": "2024-04-22T10:51:35.893495Z",
          "shell.execute_reply.started": "2024-04-22T10:51:35.893476Z"
        },
        "trusted": true
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "plt.rcParams.update({\n",
        "    \"pgf.texsystem\": \"pdflatex\",  # Change this to \"pdflatex\" or \"lualatex\"\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-22T10:51:35.895113Z",
          "iopub.status.idle": "2024-04-22T10:51:35.895553Z",
          "shell.execute_reply": "2024-04-22T10:51:35.895351Z",
          "shell.execute_reply.started": "2024-04-22T10:51:35.895333Z"
        },
        "trusted": true
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "first_months_df.query('channel == \"truexanewsua\"').set_index(['date']).resample('7d')['predicted_label'].mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-22T10:51:35.897264Z",
          "iopub.status.idle": "2024-04-22T10:51:35.897614Z",
          "shell.execute_reply": "2024-04-22T10:51:35.897465Z",
          "shell.execute_reply.started": "2024-04-22T10:51:35.897450Z"
        },
        "trusted": true
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "ncol = 2\n",
        "nrow = 3\n",
        "\n",
        "plt.figure(figsize=(16, 10))\n",
        "colors=['r', 'g']\n",
        "first_months_df['correct_prediction'] = (first_months_df['label'] == first_months_df['predicted_label']).astype(int)\n",
        "for idx, channel in enumerate(first_months_df.channel.unique()):\n",
        "    channel_df = first_months_df[first_months_df['channel'] == channel]\n",
        "    ax = plt.subplot(nrow, ncol, idx + 1)\n",
        "    \n",
        "    message_counts = (channel_df\n",
        "                      .set_index('date')\n",
        "                      .groupby(['correct_prediction'])\n",
        "                      .resample('7d')\n",
        "                      .count()['text'])\n",
        "\n",
        "    total_daily = message_counts.reset_index().groupby('date')['text'].sum()\n",
        "    xtick_labels = message_counts.loc[0].index\n",
        "\n",
        "    print(channel)\n",
        "    print(message_counts.loc[0])\n",
        "    print(message_counts.loc[1])\n",
        "    values = np.array([\n",
        "        message_counts.loc[0].values,\n",
        "        message_counts.loc[1].values\n",
        "    ])\n",
        "    bar_precents = np.array([\n",
        "         message_counts.loc[0] / total_daily * 100,\n",
        "        message_counts.loc[1] / total_daily * 100\n",
        "    ])\n",
        "    bar_texts = np.vectorize(lambda x: f\"{x:.0f}%\")(bar_precents)\n",
        "    legend_labels = [\n",
        "        'FP',\n",
        "        'TP'\n",
        "    ]\n",
        "    # draw this for each \n",
        "    stacked_bar_plot(\n",
        "        xtick_labels,\n",
        "        values,\n",
        "        bar_texts,\n",
        "        legend_labels,\n",
        "        ax=ax,\n",
        "        colors=colors\n",
        "    )\n",
        "    ax.set_title(f'Channel {channel}')\n",
        "    \n",
        "plt.tight_layout()\n",
        "# plt.savefig('plot.pgf')\n",
        "# plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-22T10:51:35.899071Z",
          "iopub.status.idle": "2024-04-22T10:51:35.899394Z",
          "shell.execute_reply": "2024-04-22T10:51:35.899251Z",
          "shell.execute_reply.started": "2024-04-22T10:51:35.899237Z"
        },
        "trusted": true
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# draw the same graph but for the model precision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-22T10:51:35.900544Z",
          "iopub.status.idle": "2024-04-22T10:51:35.900865Z",
          "shell.execute_reply": "2024-04-22T10:51:35.900720Z",
          "shell.execute_reply.started": "2024-04-22T10:51:35.900707Z"
        },
        "trusted": true
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "\n",
        "# result_matrix(sampled_inf_df.assign(\n",
        "#     predicted_label=inference_df_en_preds\n",
        "# ), ['channel'],metrics )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-22T10:51:35.902016Z",
          "iopub.status.idle": "2024-04-22T10:51:35.902369Z",
          "shell.execute_reply": "2024-04-22T10:51:35.902202Z",
          "shell.execute_reply.started": "2024-04-22T10:51:35.902188Z"
        },
        "trusted": true
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# ru_1_df = sampled_inf_df.assign(\n",
        "#     predicted_label=inference_df_en_preds\n",
        "# ).query('channel == \"HolodniyYar\"')\n",
        "# recall_score(ru_1_df['label'], ru_1_df['predicted_label'], average=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-22T10:51:35.903524Z",
          "iopub.status.idle": "2024-04-22T10:51:35.903890Z",
          "shell.execute_reply": "2024-04-22T10:51:35.903736Z",
          "shell.execute_reply.started": "2024-04-22T10:51:35.903721Z"
        },
        "trusted": true
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# condlist = [\n",
        "#     sampled_inf_df['channel'].isin([\n",
        "#         'ToBeOr_Official',\n",
        "#         'lachentyt',\n",
        "#         'truexanewsua'\n",
        "#     ]),\n",
        "#     sampled_inf_df['channel'].isin(['HolodniyYar']),\n",
        "# ]\n",
        "# valuelist = [0, 1]\n",
        "\n",
        "# result_matrix(\n",
        "#     sampled_inf_df.assign(\n",
        "#         label=np.select(\n",
        "#             condlist,\n",
        "#             valuelist\n",
        "#         ),\n",
        "#         predicted_label=inference_df_en_preds\n",
        "#     )\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-22T10:51:35.905362Z",
          "iopub.status.idle": "2024-04-22T10:51:35.905679Z",
          "shell.execute_reply": "2024-04-22T10:51:35.905535Z",
          "shell.execute_reply.started": "2024-04-22T10:51:35.905522Z"
        },
        "trusted": true
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# Do the same for other channel\n",
        "\n",
        "\n",
        "# sampled_inf_df.assign(\n",
        "#     predicted_label=inference_df_en_preds\n",
        "# ).groupby('channel').apply(partial(sample_tp_fn, sample_size=2))[['text', 'label', 'predicted_label']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test 3. Present days with translation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-22T10:51:35.907136Z",
          "iopub.status.idle": "2024-04-22T10:51:35.907487Z",
          "shell.execute_reply": "2024-04-22T10:51:35.907326Z",
          "shell.execute_reply.started": "2024-04-22T10:51:35.907312Z"
        },
        "trusted": true
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "start_date = '2023-12-01'\n",
        "end_date = '2024-02-08'\n",
        "inference_df = story_df.loc[start_date:end_date].reset_index('date')\n",
        "inference_df['date-only'] = inference_df['date'].dt.date\n",
        "plot_messages_by_date(inference_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-22T10:51:35.908833Z",
          "iopub.status.idle": "2024-04-22T10:51:35.909195Z",
          "shell.execute_reply": "2024-04-22T10:51:35.909034Z",
          "shell.execute_reply.started": "2024-04-22T10:51:35.909012Z"
        },
        "trusted": true
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# dec_jan_24 = calculate_time_dynamics(story_df,\n",
        "#                                      start_date='2024-01-01',\n",
        "#                                      end_date='2024-02-08',\n",
        "#                                      model=model,\n",
        "#                                      tokenizer=tokenizer,\n",
        "#                                      batch_size=batch_size,\n",
        "#                                      device=device)\n",
        "\n",
        "# plot_messages_by_date(dec_jan_24, hue='predicted_label', col_order=['HolodniyYar', 'truexanewsua', 'ToBeOr_Official', 'lachentyt' ])\n",
        "# print(result_matrix(dec_jan_24, ['channel'],metrics ))\n",
        "# print(dec_jan_24.groupby('channel').apply(partial(sample_tp_fn, sample_size=2))[['text', 'label', 'predicted_label']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-22T10:51:35.910434Z",
          "iopub.status.idle": "2024-04-22T10:51:35.910744Z",
          "shell.execute_reply": "2024-04-22T10:51:35.910600Z",
          "shell.execute_reply.started": "2024-04-22T10:51:35.910588Z"
        },
        "trusted": true
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "\n",
        "translator = Translator()\n",
        "\n",
        "start_date = '2023-12-01'\n",
        "end_date = '2024-02-08'\n",
        "\n",
        "current_time_df = calculate_time_dynamics(story_df,\n",
        "                                     start_date=start_date,\n",
        "                                     end_date=end_date,\n",
        "                                     model=model,\n",
        "                                     tokenizer=tokenizer,\n",
        "                                     batch_size=batch_size,\n",
        "                                     device=device)\n",
        "\n",
        "plot_messages_by_date(current_time_df, hue='predicted_label', col_order=['HolodniyYar', 'truexanewsua', 'ToBeOr_Official', 'lachentyt' ])\n",
        "display(result_matrix(current_time_df, ['channel'],metrics ))\n",
        "display(current_time_df.groupby('channel').apply(partial(sample_tp_fn, sample_size=2))[['text', 'label', 'predicted_label']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Analysis of particular news topics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-22T10:51:35.912537Z",
          "iopub.status.idle": "2024-04-22T10:51:35.912966Z",
          "shell.execute_reply": "2024-04-22T10:51:35.912761Z",
          "shell.execute_reply.started": "2024-04-22T10:51:35.912742Z"
        },
        "trusted": true
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "## 11 Nov\n",
        "# Find all text messages that contains херсон in it \n",
        "# any more efficient ways to do it\n",
        "def get_rows_that_contain_topic(df, start_date, end_date, keywords):\n",
        "    df = df.loc[start_date:end_date]\n",
        "    keywords = set(keywords)\n",
        "    \n",
        "    def contains_topic(text) -> bool:\n",
        "        for i in text.lower().split():\n",
        "            if i in keywords:\n",
        "                return True\n",
        "            \n",
        "        return False\n",
        "    return df[df['text'].apply(contains_topic)]\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-22T10:51:35.914641Z",
          "iopub.status.idle": "2024-04-22T10:51:35.915112Z",
          "shell.execute_reply": "2024-04-22T10:51:35.914880Z",
          "shell.execute_reply.started": "2024-04-22T10:51:35.914862Z"
        },
        "trusted": true
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# This keywords were generated by ChatGPT\n",
        "\n",
        "keywords = [\"херсон\", \"херсона\", \"херсону\", \"херсон\", \"херсоном\", \"херсоні\", \"херсоне\"]\n",
        "kherson_df = get_rows_that_contain_topic(story_df,\n",
        "                           start_date='2022-10-01',\n",
        "                           end_date='2022-12-01',\n",
        "                           keywords=keywords)\n",
        "kherson_df.index.name = 'date'\n",
        "kherson_df.groupby(['channel','label'])['text'].agg('count')\n",
        "kherson_df = calculate_time_dynamics(kherson_df,\n",
        "                                     start_date='2022-10-01',\n",
        "                                     end_date='2022-12-01',\n",
        "                                     model=model,\n",
        "                                     tokenizer=tokenizer,\n",
        "                                     batch_size=batch_size,\n",
        "                                     device=device)\n",
        "\n",
        "plot_messages_by_date(kherson_df, hue='predicted_label', col_order=['HolodniyYar', 'truexanewsua', 'ToBeOr_Official', 'lachentyt' ])\n",
        "print(result_matrix(kherson_df, ['channel'],metrics ))\n",
        "kherson_df.groupby('channel').apply(partial(sample_tp_fn, sample_size=1))[['text', 'original_text', 'label', 'predicted_label']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-22T10:51:35.916669Z",
          "iopub.status.idle": "2024-04-22T10:51:35.917111Z",
          "shell.execute_reply": "2024-04-22T10:51:35.916893Z",
          "shell.execute_reply.started": "2024-04-22T10:51:35.916874Z"
        },
        "trusted": true
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "output_df = (result_matrix(first_months_df, ['channel'],metrics )[['recall']]\n",
        "    .merge(result_matrix(kherson_df, ['channel'],metrics)[[ 'recall']],on=['label','channel'], \n",
        "        suffixes=('', ' Kherson Sample'))\n",
        "    .merge(result_matrix(current_time_df, ['channel'],metrics)[[ 'recall']],on=['label','channel'], \n",
        "        suffixes=(' Fist Month', ' Current Time'))\n",
        "    .reset_index()\n",
        "    .rename(columns={\n",
        "        'recall Fist Month': 'Recall First Months',\n",
        "        'recall Kherson Sample': 'Recall Kherson Sample',\n",
        "        'recall Current Time': 'Recall Current Time',\n",
        "    })\n",
        "    .set_index(['label', 'channel'])\n",
        "            .sort_index(ascending=[True, True])\n",
        "             \n",
        "#  .sort_index()[['recall']]\n",
        "#  .rename(columns={ 'recall' : 'Recall Score'})\n",
        " )\n",
        "\n",
        "output_df.index.names = ['Label', 'Channel']\n",
        "# print(output_df.to_latex(float_format='%.2f'))\n",
        "output_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Playground (this can be deleted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-22T10:51:35.918559Z",
          "iopub.status.idle": "2024-04-22T10:51:35.918976Z",
          "shell.execute_reply": "2024-04-22T10:51:35.918779Z",
          "shell.execute_reply.started": "2024-04-22T10:51:35.918760Z"
        },
        "trusted": true
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "def read_experiment_data(experiment_data_path):\n",
        "    X_train = pd.read_csv(f'{experiment_data_path}/X_train.csv')\n",
        "    X_test = pd.read_csv(f'{experiment_data_path}/X_test.csv')\n",
        "    X_eval = pd.read_csv(f'{experiment_data_path}/X_eval.csv')\n",
        "\n",
        "    y_train_preds = pd.read_csv(f'{experiment_data_path}/y_train_preds.csv')\n",
        "    y_test_preds = pd.read_csv(f'{experiment_data_path}/y_test_preds.csv')\n",
        "    y_eval_preds = pd.read_csv(f'{experiment_data_path}/y_eval_preds.csv')\n",
        "    X = pd.concat([\n",
        "        X_train.assign(\n",
        "            predicted_label=y_train_preds.values,\n",
        "            subset='train'\n",
        "        ),\n",
        "        X_test.assign(\n",
        "            predicted_label=y_test_preds.values,\n",
        "            subset='test'\n",
        "        ),\n",
        "        X_eval.assign(\n",
        "            predicted_label=y_eval_preds.values,\n",
        "            subset='eval'\n",
        "        )\n",
        "        ])\n",
        "    return X\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-22T10:51:35.921148Z",
          "iopub.status.idle": "2024-04-22T10:51:35.921457Z",
          "shell.execute_reply": "2024-04-22T10:51:35.921320Z",
          "shell.execute_reply.started": "2024-04-22T10:51:35.921307Z"
        },
        "trusted": true
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "from IPython.display import display\n",
        "ex1 = read_experiment_data('/kaggle/input/predictions-from-the-working-model')\n",
        "display()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-22T10:51:35.922504Z",
          "iopub.status.idle": "2024-04-22T10:51:35.922848Z",
          "shell.execute_reply": "2024-04-22T10:51:35.922697Z",
          "shell.execute_reply.started": "2024-04-22T10:51:35.922683Z"
        },
        "trusted": true
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "def style_multilevel(df, level=0, prop='border-bottom: 2px solid black;'):\n",
        "    \"\"\"\n",
        "    Apply a style to multi-level column headers.\n",
        "    \n",
        "    Args:\n",
        "    df (DataFrame): The DataFrame to style.\n",
        "    level (int): The level of the multi-index to apply the style to.\n",
        "    prop (str): The CSS property to apply.\n",
        "    \"\"\"\n",
        "    # Check if DataFrame has a multi-index\n",
        "    if isinstance(df.columns, pd.MultiIndex):\n",
        "        # Generate the styles for each column\n",
        "        return df.style.apply(lambda x: [''] + [prop if i else '' for i in df.columns.get_level_values(level).duplicated(keep='first')], axis=1)\n",
        "    else:\n",
        "        return df.style\n",
        "   \n",
        "\n",
        "# Apply the styling function\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-22T10:51:35.924773Z",
          "iopub.status.idle": "2024-04-22T10:51:35.925150Z",
          "shell.execute_reply": "2024-04-22T10:51:35.924954Z",
          "shell.execute_reply.started": "2024-04-22T10:51:35.924940Z"
        },
        "trusted": true
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "ex1_res_df= (result_matrix(\n",
        "            ex1, \n",
        "              ['sourced_lang'], \n",
        "              {k:v for k,v in metrics.items() if k in ['precision', 'recall', 'f1', 'count']}, \n",
        "              use_subsets=True\n",
        "             )\n",
        "    .T\n",
        "    .reset_index()\n",
        "    .set_index(['subset', 'level_0'])\n",
        "    .sort_index(ascending=[False, False])\n",
        "    .T)\n",
        "\n",
        "ex1_res_df.round(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-22T10:51:35.926672Z",
          "iopub.status.idle": "2024-04-22T10:51:35.927016Z",
          "shell.execute_reply": "2024-04-22T10:51:35.926851Z",
          "shell.execute_reply.started": "2024-04-22T10:51:35.926837Z"
        },
        "trusted": true
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "ex1_res_df.columns.names = ['subset' ,'metrics']\n",
        "print(ex1_res_df.to_latex(float_format='%.2f'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-22T10:51:35.928569Z",
          "iopub.status.idle": "2024-04-22T10:51:35.928892Z",
          "shell.execute_reply": "2024-04-22T10:51:35.928749Z",
          "shell.execute_reply.started": "2024-04-22T10:51:35.928735Z"
        },
        "trusted": true
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "ex1.groupby(['label', 'sourced_lang'])['channel'].unique().apply(lambda x: len(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exploring model choices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-22T10:51:35.930095Z",
          "iopub.status.idle": "2024-04-22T10:51:35.930402Z",
          "shell.execute_reply": "2024-04-22T10:51:35.930264Z",
          "shell.execute_reply.started": "2024-04-22T10:51:35.930252Z"
        },
        "trusted": true
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "explore_model_choices(first_months_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-22T10:51:35.931843Z",
          "iopub.status.idle": "2024-04-22T10:51:35.932178Z",
          "shell.execute_reply": "2024-04-22T10:51:35.932032Z",
          "shell.execute_reply.started": "2024-04-22T10:51:35.932012Z"
        },
        "trusted": true
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "print(pd.DataFrame([\n",
        "    {\n",
        "        'Channel': 'HolodniyYar',\n",
        "        'Presumed label': 1,\n",
        "        'Predicted label': 0,\n",
        "        'Original text': 'Верное решение. Семьи ждут их дома!',\n",
        "        'Translated text': 'The families are waiting for them at home!'\n",
        "    },\n",
        "        {\n",
        "        'Channel': 'HolodniyYar',\n",
        "        'Presumed label': 1,\n",
        "        'Predicted label': 0,\n",
        "        'Original text': '❗️Кажется для властей Украины всё\\n\\nНеожиданно на спутниковых снимках от Maxar Technologies увидели колонну бронетехники длинной 64 км свыше чуть западнее Киева. \\n\\nДлина колонны по данным Maxar составляет порядка 64 км🤷‍♂\\n\\nКак и предупреждали Зеленского, за безответственность настанет расплата, а за самообман расплата бывает самой горькой.\\n\\nНапомним, уже с завтрашнего дня ВС РФ может начать отлов военных преступников с помощью серий спецмероприятий',\n",
        "        'Translated text': 'It seems to the Ukrainian authorities that all of the satellite images from Maksar Technologies have seen a column of armoured equipment of a length of 64 km over just west of Kiev. The length of the column, according to the data from Makhar, is about 64 km. As Zelensky was warned, there will be a payback for irresponsibleness, and self-deception can be the bitterest'\n",
        "    },\n",
        "        \n",
        "        {\n",
        "        'Channel': 'HolodniyYar',\n",
        "        'Presumed label': 1,\n",
        "        'Predicted label': 1,\n",
        "        'Original text': ' ⚡️⚡️⚡️🇺🇦 Вот тебе и допомога!\\n\\nЯ писал раньше про то, что Германия поставит нам тяжелое вооружение сомнительного качества. Но они превзошли себя!\\n\\nГермания по указанию канцлера Шольца исключила из списка военной помощи Украине все тяжелое вооружение, список сократился с 48 до 24 страниц - передает немецкое издание Билд.\\n\\nОчередной пафосный жест Европы пошел ко дну! \\n\\n@HolodniyYar',\n",
        "        'Translated text': \"I've written earlier about the fact that Germany will give us a difficult weapon of questionable quality, but they have outdone themselves! Germany, at the instruction of Chancellor Scholtz, has removed all heavy weapons from Ukraine's military assistance list, the list has been reduced from 48 to 24 pages - transmitting the German edition of Bild. Europe's next pathological gesture has gone down! @HolodnyYar\"\n",
        "    }\n",
        "])[[ 'Channel','Presumed label', 'Predicted label', 'Translated text']].to_latex())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-22T10:51:35.933164Z",
          "iopub.status.idle": "2024-04-22T10:51:35.933465Z",
          "shell.execute_reply": "2024-04-22T10:51:35.933328Z",
          "shell.execute_reply.started": "2024-04-22T10:51:35.933316Z"
        },
        "trusted": true
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "explore_model_choices(current_time_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-22T10:51:35.934833Z",
          "iopub.status.idle": "2024-04-22T10:51:35.935178Z",
          "shell.execute_reply": "2024-04-22T10:51:35.935031Z",
          "shell.execute_reply.started": "2024-04-22T10:51:35.935012Z"
        },
        "trusted": true
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "lala_df=  pd.DataFrame({\n",
        "        'text': [\n",
        "        \"I've written earlier about the fact that Germany will give us a difficult \\\n",
        "            weapon of questionable quality, but they have outdone themselves! Germany, \\\n",
        "            at the instruction of Chancellor Scholtz, has removed all heavy weapons\\\n",
        "            from Ukraine's military assistance list, the list has been reduced from 48 to 24 pages -\\\n",
        "            transmitting the German edition of Bild. Europe's next \\\n",
        "            pathological gesture has gone down! @s\"\n",
        "        ],\n",
        "        'label': [1]\n",
        "    })\n",
        "# display(translator.translate(['❗️Кажется для властей Украины всё'], source_lang='ru')[0])\n",
        "score_test, X_test_preds = get_model_score_and_predictions(\n",
        "    model,\n",
        "    tokenizer,\n",
        "  lala_df,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "X_test_preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyMH4mjiIfz+qCKCicNiJrCZ",
      "collapsed_sections": [
        "xinNpVFYItsZ"
      ],
      "gpuType": "T4",
      "mount_file_id": "15rRLCIoTfXf0m8Aaf6Sn-bD2bn5uw6Pb",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 4830463,
          "sourceId": 8163857,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30673,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "005fe87c2b6e4cdf95dc52584f0e36a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b90228ad47b6461f8ae168d4cba3d6a2",
            "placeholder": "​",
            "style": "IPY_MODEL_5ee54f32909d447681fb3eb489e1280f",
            "value": "100%"
          }
        },
        "0098ab8987c646399b766a9fd9ff7c4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "00db54be132a4270a0b7d6562b01009c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01ed921c1f754a9aba040750404bc8a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2136675b9b904e728ff3150e89439008": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2c9832d516bd48bfa6eb2a2542a2e337": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e49e900f3d24f618bbdbe965f357119": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "367512efa0e9408494665af91efb7e9f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fe06552a852439ca27522ed683d9592": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "510a9e0483ad4784a35b36195a4572d8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "512e33f1cade469982524365ffbe4f64": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5d414197e5e04afe878fd4826e3e1065",
              "IPY_MODEL_c936766bf308443b968f26656f6bd00a",
              "IPY_MODEL_e1728fb56f084b90a720d13d7e469f1f"
            ],
            "layout": "IPY_MODEL_72d725bb4e764292b3585ede20b14773"
          }
        },
        "56242f9fb40f42f18c5bd4c87568991a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_72b7b6cdfde7430fa47546e530f344d0",
            "placeholder": "​",
            "style": "IPY_MODEL_7c565513611846eda61d0d20c8349ae1",
            "value": " 43/43 [00:07&lt;00:00,  6.29it/s]"
          }
        },
        "59f28e2d696a4a03b35599487b8a0b21": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f488b3687a044755a919ebfa44ffd07d",
            "max": 474,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2e49e900f3d24f618bbdbe965f357119",
            "value": 474
          }
        },
        "5b2df4e306604475b1a235dcc8400730": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_78425314baec4e48a4118f2b262a4833",
              "IPY_MODEL_59f28e2d696a4a03b35599487b8a0b21",
              "IPY_MODEL_e1816bdf58ed43049b5c88d5dc42d935"
            ],
            "layout": "IPY_MODEL_2c9832d516bd48bfa6eb2a2542a2e337"
          }
        },
        "5d38b9d79f2f4b85b608b3f68b91c538": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d414197e5e04afe878fd4826e3e1065": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_367512efa0e9408494665af91efb7e9f",
            "placeholder": "​",
            "style": "IPY_MODEL_01ed921c1f754a9aba040750404bc8a4",
            "value": "Detecting lang: 100%"
          }
        },
        "5ee54f32909d447681fb3eb489e1280f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7113b34654e44271ac56d85b59145e02": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72b7b6cdfde7430fa47546e530f344d0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72d725bb4e764292b3585ede20b14773": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "753b9ca5a3dd4a78997cb3fd74e84153": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "763585ca85514d45ba693c6260debfe3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d93717835fbc44669caac187b8278681",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2136675b9b904e728ff3150e89439008",
            "value": 1000
          }
        },
        "78425314baec4e48a4118f2b262a4833": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb1426f76c4a4ed69d92ce4cc5ad66c3",
            "placeholder": "​",
            "style": "IPY_MODEL_5d38b9d79f2f4b85b608b3f68b91c538",
            "value": "100%"
          }
        },
        "7c565513611846eda61d0d20c8349ae1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7d7ee59aef14499584ae9db708787b52": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ad19f8c98c44ca381f5c99adb8f83d7",
            "placeholder": "​",
            "style": "IPY_MODEL_d964d8a1279649bf9677745aa4ad1aba",
            "value": " 1000/1000 [02:43&lt;00:00,  6.21it/s]"
          }
        },
        "8ad19f8c98c44ca381f5c99adb8f83d7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d9269dda50246559dfd84bdba04d1df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c94537ec7bf747968da18320a50e6fe0",
              "IPY_MODEL_763585ca85514d45ba693c6260debfe3",
              "IPY_MODEL_7d7ee59aef14499584ae9db708787b52"
            ],
            "layout": "IPY_MODEL_3fe06552a852439ca27522ed683d9592"
          }
        },
        "8ded856a208444a589d045058a313293": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ee5dffca60d4274a4b0a7b24a5602bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a716c674443c4289897b319960a78380": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_510a9e0483ad4784a35b36195a4572d8",
            "max": 43,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_753b9ca5a3dd4a78997cb3fd74e84153",
            "value": 43
          }
        },
        "aab6516f00104b808b4e2153fb95b520": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae84a1df110a473e9d8d0784c26931a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b90228ad47b6461f8ae168d4cba3d6a2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c90ea7bf7d78427e9fe32d3352d18128": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_005fe87c2b6e4cdf95dc52584f0e36a7",
              "IPY_MODEL_a716c674443c4289897b319960a78380",
              "IPY_MODEL_56242f9fb40f42f18c5bd4c87568991a"
            ],
            "layout": "IPY_MODEL_d97a2a1e0aab470689354be9ee50cfbc"
          }
        },
        "c936766bf308443b968f26656f6bd00a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00db54be132a4270a0b7d6562b01009c",
            "max": 16792,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8ee5dffca60d4274a4b0a7b24a5602bc",
            "value": 16792
          }
        },
        "c94537ec7bf747968da18320a50e6fe0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ded856a208444a589d045058a313293",
            "placeholder": "​",
            "style": "IPY_MODEL_ae84a1df110a473e9d8d0784c26931a9",
            "value": "100%"
          }
        },
        "d93717835fbc44669caac187b8278681": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d964d8a1279649bf9677745aa4ad1aba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d97a2a1e0aab470689354be9ee50cfbc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1728fb56f084b90a720d13d7e469f1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7113b34654e44271ac56d85b59145e02",
            "placeholder": "​",
            "style": "IPY_MODEL_aab6516f00104b808b4e2153fb95b520",
            "value": " 16792/16792 [00:00&lt;00:00, 19983.78it/s]"
          }
        },
        "e1816bdf58ed43049b5c88d5dc42d935": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ffa0864967bd4602b9e89bb280401191",
            "placeholder": "​",
            "style": "IPY_MODEL_0098ab8987c646399b766a9fd9ff7c4a",
            "value": " 474/474 [03:48&lt;00:00,  2.29it/s]"
          }
        },
        "f488b3687a044755a919ebfa44ffd07d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb1426f76c4a4ed69d92ce4cc5ad66c3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffa0864967bd4602b9e89bb280401191": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
